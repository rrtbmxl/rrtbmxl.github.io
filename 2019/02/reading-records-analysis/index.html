

  
    
  


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.54.0 with theme Tranquilpeak 0.4.3-BETA">
    <title>11年-19年读书记录分析</title>
    <meta name="author" content="孟祥良">
    <meta name="keywords" content="tech">

    <link rel="icon" href="/favicon.png">
    

    
    <meta name="description" content="大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.">
    <meta property="og:description" content="大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="11年-19年读书记录分析">
    <meta property="og:url" content="/2019/02/reading-records-analysis/">
    <meta property="og:site_name" content="RPG">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="RPG">
    <meta name="twitter:description" content="大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=640">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">RPG</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">孟祥良</h4>
        
          <h5 class="sidebar-profile-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/rrtbmxl/rrtbmxl.github.io">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      11年-19年读书记录分析
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-02-16T00:00:00Z">
        
  February 16, 2019

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              


<p>大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。</p>
<p>我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。</p>
<p>但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：</p>
<ol style="list-style-type: decimal">
<li><p>国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。</p></li>
<li><p>技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。</p></li>
<li><p>电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。</p></li>
<li><p>太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。</p></li>
</ol>
<p>去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。</p>
<p>首先还是载入分析需要用到的包：</p>
<pre class="r"><code>library(tidyverse)
library(readxl)
library(knitr)</code></pre>
<p>然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：</p>
<pre class="r"><code>book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% 
  select(year = 2, name = 4, publisher = 6, author = 7, 
         country = 8, dynasty = 9, classification = 10, language = 11, 
         price = 12, page = 13, words = 14, manner = 15) %&gt;% 
  mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,
                           language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,
                           TRUE ~ words),
         words = ifelse(manner == &#39;书内&#39;, words*.8, words*.6),
         words = round(words, 0), 
         price = as.numeric(price) %&gt;% round(1)) %&gt;% 
  select(-manner)</code></pre>
<p>清洗后的数据是这样的，随机显示了10本（这里本来想用<code>DT</code>包来生成全部内容的，但我用的<code>blogdown</code>主题似乎并不支持）：</p>
<pre class="r"><code>set.seed(20190216)
book %&gt;% sample_n(10) %&gt;% 
  arrange(year) %&gt;% kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">year</th>
<th align="left">name</th>
<th align="left">publisher</th>
<th align="left">author</th>
<th align="left">country</th>
<th align="left">dynasty</th>
<th align="left">classification</th>
<th align="left">language</th>
<th align="right">price</th>
<th align="right">page</th>
<th align="right">words</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2012</td>
<td align="left">爱弥儿（下）</td>
<td align="left">中华书局</td>
<td align="left">卢梭</td>
<td align="left">法国</td>
<td align="left">/</td>
<td align="left">教育</td>
<td align="left">汉语</td>
<td align="right">24.0</td>
<td align="right">440</td>
<td align="right">199056</td>
</tr>
<tr class="even">
<td align="left">2012</td>
<td align="left">教育漫话</td>
<td align="left">教育科学出版社</td>
<td align="left">洛克</td>
<td align="left">英国</td>
<td align="left">/</td>
<td align="left">教育</td>
<td align="left">汉语</td>
<td align="right">15.0</td>
<td align="right">193</td>
<td align="right">120000</td>
</tr>
<tr class="odd">
<td align="left">2012</td>
<td align="left">徐志摩散文精选</td>
<td align="left">长江文艺出版社</td>
<td align="left">徐志摩</td>
<td align="left">中国</td>
<td align="left">现代</td>
<td align="left">文学</td>
<td align="left">汉语</td>
<td align="right">22.0</td>
<td align="right">301</td>
<td align="right">121363</td>
</tr>
<tr class="even">
<td align="left">2012</td>
<td align="left">小城三月</td>
<td align="left">长江文艺出版社</td>
<td align="left">萧红</td>
<td align="left">中国</td>
<td align="left">现代</td>
<td align="left">小说</td>
<td align="left">汉语</td>
<td align="right">17.0</td>
<td align="right">268</td>
<td align="right">108058</td>
</tr>
<tr class="odd">
<td align="left">2014</td>
<td align="left">心理学与生活</td>
<td align="left">人民邮电出版社</td>
<td align="left">格里格/津巴多</td>
<td align="left">美国</td>
<td align="left">/</td>
<td align="left">心理学</td>
<td align="left">汉语</td>
<td align="right">88.0</td>
<td align="right">621</td>
<td align="right">1012800</td>
</tr>
<tr class="even">
<td align="left">2014</td>
<td align="left">谈美书简</td>
<td align="left">中华书局</td>
<td align="left">朱光潜</td>
<td align="left">中国</td>
<td align="left">现代</td>
<td align="left">艺术</td>
<td align="left">汉语</td>
<td align="right">13.0</td>
<td align="right">136</td>
<td align="right">72000</td>
</tr>
<tr class="odd">
<td align="left">2015</td>
<td align="left">现代心理学史</td>
<td align="left">中国轻工业出版社</td>
<td align="left">杜安·P·舒尔茨/悉妮·埃伦·舒尔茨</td>
<td align="left">美国</td>
<td align="left">/</td>
<td align="left">心理学</td>
<td align="left">汉语</td>
<td align="right">75.0</td>
<td align="right">513</td>
<td align="right">334400</td>
</tr>
<tr class="even">
<td align="left">2016</td>
<td align="left">卡夫卡小说全集 Ⅲ</td>
<td align="left">人民文学出版社</td>
<td align="left">卡夫卡</td>
<td align="left">奥匈帝国</td>
<td align="left">/</td>
<td align="left">小说</td>
<td align="left">汉语</td>
<td align="right">29.3</td>
<td align="right">326</td>
<td align="right">240210</td>
</tr>
<tr class="odd">
<td align="left">2016</td>
<td align="left">庄子今注今译（下）</td>
<td align="left">中华书局</td>
<td align="left">陈鼓应</td>
<td align="left">中国</td>
<td align="left">当代</td>
<td align="left">哲学</td>
<td align="left">古汉</td>
<td align="right">32.0</td>
<td align="right">335</td>
<td align="right">187017</td>
</tr>
<tr class="even">
<td align="left">2017</td>
<td align="left">八十天环游地球</td>
<td align="left">安徽教育出版社</td>
<td align="left">儒勒·凡尔纳</td>
<td align="left">法国</td>
<td align="left">/</td>
<td align="left">小说</td>
<td align="left">汉语</td>
<td align="right">22.0</td>
<td align="right">259</td>
<td align="right">168000</td>
</tr>
</tbody>
</table>
<p>下面依次进行分析：</p>
<div class="section level3">
<h3>年份</h3>
<pre class="r"><code>book %&gt;% group_by(year) %&gt;% 
  count(sort = TRUE) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">year</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2014</td>
<td align="right">87</td>
</tr>
<tr class="even">
<td align="left">2012</td>
<td align="right">82</td>
</tr>
<tr class="odd">
<td align="left">2016</td>
<td align="right">78</td>
</tr>
<tr class="even">
<td align="left">2013</td>
<td align="right">76</td>
</tr>
<tr class="odd">
<td align="left">2015</td>
<td align="right">56</td>
</tr>
<tr class="even">
<td align="left">2017</td>
<td align="right">47</td>
</tr>
<tr class="odd">
<td align="left">2018</td>
<td align="right">18</td>
</tr>
<tr class="even">
<td align="left">2011</td>
<td align="right">15</td>
</tr>
<tr class="odd">
<td align="left">2019</td>
<td align="right">6</td>
</tr>
</tbody>
</table>
<p>可以看到，看书最多的年份是2014年，其次是12年和16年。14年我正在准备考研，这一年大概是我一生中最充实的一年了，算上考研教材的话，那年我应该看了120本书。除去11年和19年，看书最少的是去年。去年上半年在忙着毕业和找工作，而下半年则在忙着适应工作，没能空出太多的时间看书，不过以后应该不会了。</p>
<p>再算个平均数，这里把11年和19年排除在外：</p>
<pre class="r"><code>book %&gt;% filter(!year %in% c(2011, 2019)) %&gt;% 
  summarise(mean = nrow(.)/n_distinct(year)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">63.42857</td>
</tr>
</tbody>
</table>
<p>平均起来，我每年能看63本书，也就是说，我基本上能保证每月5本书。</p>
</div>
<div class="section level3">
<h3>出版社</h3>
<pre class="r"><code>book %&gt;% group_by(publisher) %&gt;% 
  count(sort = TRUE) %&gt;% 
  filter(n &gt; 10) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">publisher</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">中华书局</td>
<td align="right">101</td>
</tr>
<tr class="even">
<td align="left">人民文学出版社</td>
<td align="right">68</td>
</tr>
<tr class="odd">
<td align="left">商务印书馆</td>
<td align="right">41</td>
</tr>
<tr class="even">
<td align="left">人民邮电出版社</td>
<td align="right">26</td>
</tr>
<tr class="odd">
<td align="left">译林出版社</td>
<td align="right">23</td>
</tr>
<tr class="even">
<td align="left">天津古籍出版社</td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td align="left">中央编译出版社</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="left">安徽教育出版社</td>
<td align="right">11</td>
</tr>
<tr class="odd">
<td align="left">上海译文出版社</td>
<td align="right">11</td>
</tr>
</tbody>
</table>
<p>前五个出版社的书占了大概一半，我尤其喜欢中华书局的书啊！</p>
</div>
<div class="section level3">
<h3>作者</h3>
<pre class="r"><code>book %&gt;% group_by(author) %&gt;% 
  count(sort = TRUE) %&gt;% 
  filter(n &gt; 4) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">author</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">司马迁</td>
<td align="right">22</td>
</tr>
<tr class="even">
<td align="left">鲁迅</td>
<td align="right">17</td>
</tr>
<tr class="odd">
<td align="left">陈鼓应</td>
<td align="right">13</td>
</tr>
<tr class="even">
<td align="left">儒勒·凡尔纳</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="left">莎士比亚</td>
<td align="right">11</td>
</tr>
<tr class="even">
<td align="left">蒙台梭利</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="left">柏拉图</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">不详</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="left">李伯钦/李肇祥</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">George R.R.Martin</td>
<td align="right">7</td>
</tr>
<tr class="odd">
<td align="left">J.K.Rowling</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="left">卢梭</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="left">蒙田</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="left">亚里士多德</td>
<td align="right">6</td>
</tr>
<tr class="odd">
<td align="left">王弼</td>
<td align="right">5</td>
</tr>
</tbody>
</table>
<p>太史公最多，因为看过两个版本的《史记》，一个是文白对照的版本，九大本，看了两遍，另一个是文言版本，四大本，看了一遍，然而内容实在太多，大部分看过就忘了。鲁迅第二，因为看了一遍《鲁迅全集》，希望以后能有时间，打乱卷次的顺序，从日记、书信和作品三个方面按着时间的推进再看一遍。后面是陈鼓应和凡尔纳，陈鼓应和《老子注译及评介》和《庄子今注今译》是我最喜欢的几本书，而凡尔纳的小说全集，也粗略地看过一遍。</p>
</div>
<div class="section level3">
<h3>国别</h3>
<pre class="r"><code>book %&gt;% group_by(country) %&gt;% 
  count(sort = TRUE) %&gt;% 
  filter(n &gt; 4) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">country</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">中国</td>
<td align="right">158</td>
</tr>
<tr class="even">
<td align="left">美国</td>
<td align="right">85</td>
</tr>
<tr class="odd">
<td align="left">英国</td>
<td align="right">65</td>
</tr>
<tr class="even">
<td align="left">法国</td>
<td align="right">48</td>
</tr>
<tr class="odd">
<td align="left">古希腊</td>
<td align="right">19</td>
</tr>
<tr class="even">
<td align="left">意大利</td>
<td align="right">19</td>
</tr>
<tr class="odd">
<td align="left">德国</td>
<td align="right">17</td>
</tr>
<tr class="even">
<td align="left">日本</td>
<td align="right">9</td>
</tr>
<tr class="odd">
<td align="left">古罗马</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">奥地利</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="left">西班牙</td>
<td align="right">5</td>
</tr>
</tbody>
</table>
<p>自然是中国的最多，不过跟英语国家加起来进行对比的话，也没有多多少。</p>
</div>
<div class="section level3">
<h3>朝代</h3>
<pre class="r"><code>book %&gt;% group_by(dynasty) %&gt;% 
  count(sort = TRUE) %&gt;% 
  filter(dynasty != &#39;/&#39;, n &gt; 2) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">dynasty</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">当代</td>
<td align="right">46</td>
</tr>
<tr class="even">
<td align="left">现代</td>
<td align="right">44</td>
</tr>
<tr class="odd">
<td align="left">汉朝</td>
<td align="right">23</td>
</tr>
<tr class="even">
<td align="left">先秦</td>
<td align="right">22</td>
</tr>
<tr class="odd">
<td align="left">魏朝</td>
<td align="right">5</td>
</tr>
<tr class="even">
<td align="left">明朝</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">清朝</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="left">宋朝</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="left">唐朝</td>
<td align="right">3</td>
</tr>
</tbody>
</table>
<p>画出来折线图的话，会是U形的。2000年前和最近100年的，看的比较多，以后似乎也应该多看看两个时间段之间的。</p>
</div>
<div class="section level3">
<h3>分类</h3>
<pre class="r"><code>book %&gt;% group_by(classification) %&gt;% 
  count(sort = TRUE) %&gt;% 
  filter(n &gt; 4) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">classification</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">小说</td>
<td align="right">123</td>
</tr>
<tr class="even">
<td align="left">哲学</td>
<td align="right">96</td>
</tr>
<tr class="odd">
<td align="left">文学</td>
<td align="right">91</td>
</tr>
<tr class="even">
<td align="left">历史</td>
<td align="right">55</td>
</tr>
<tr class="odd">
<td align="left">心理学</td>
<td align="right">49</td>
</tr>
<tr class="even">
<td align="left">教育</td>
<td align="right">24</td>
</tr>
<tr class="odd">
<td align="left">社会科学</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="left">方法论</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="left">自然科学</td>
<td align="right">5</td>
</tr>
</tbody>
</table>
<p>我看的书主要集中在文史哲三大类上，其中小说数量最多，就把它从文学中拿了出来，自成一类。另外，因为我没有记录国产的心理学教材，所以心理学书籍的数量相对较少，实际上应该是比历史类的书多的。</p>
</div>
<div class="section level3">
<h3>语言</h3>
<pre class="r"><code>book %&gt;% group_by(language) %&gt;% 
  count(sort = TRUE) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">language</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">汉语</td>
<td align="right">350</td>
</tr>
<tr class="even">
<td align="left">古汉</td>
<td align="right">55</td>
</tr>
<tr class="odd">
<td align="left">英语</td>
<td align="right">28</td>
</tr>
<tr class="even">
<td align="left">古语</td>
<td align="right">21</td>
</tr>
<tr class="odd">
<td align="left">英汉</td>
<td align="right">11</td>
</tr>
</tbody>
</table>
<p>古语是指纯文言的，古汉是指文白参照的，英语和英汉的也是这样，不过看的最多的自然还是现代汉语的。另外，在对字数进行统计时，我根据语言进行了校正，具体就是古汉和英汉的在原有字数基础上乘以1.3，而古语和英语的在原有字数基础上乘以2。</p>
</div>
<div class="section level3">
<h3>价格</h3>
<pre class="r"><code>book %&gt;% mutate(price = as.numeric(price)) %&gt;% 
  summarise(total = sum(price), avg = mean(price)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">total</th>
<th align="right">avg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">16601</td>
<td align="right">35.70108</td>
</tr>
</tbody>
</table>
<p>这些书的总价格大概是一万六千多，平均起来，每本35块7，但除了很少的几本书是在新华书店按原价买的，其余的书基本上都是打折的，而且折扣也都很大，所以实际上，这些年我也就看了一万块钱左右的书。</p>
<pre class="r"><code>book %&gt;% mutate(price = as.numeric(price)) %&gt;% 
  group_by(year) %&gt;% 
  summarise(total = sum(price)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">year</th>
<th align="right">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2011</td>
<td align="right">364.8</td>
</tr>
<tr class="even">
<td align="left">2012</td>
<td align="right">1933.9</td>
</tr>
<tr class="odd">
<td align="left">2013</td>
<td align="right">1932.1</td>
</tr>
<tr class="even">
<td align="left">2014</td>
<td align="right">3586.8</td>
</tr>
<tr class="odd">
<td align="left">2015</td>
<td align="right">2816.3</td>
</tr>
<tr class="even">
<td align="left">2016</td>
<td align="right">3221.3</td>
</tr>
<tr class="odd">
<td align="left">2017</td>
<td align="right">1636.2</td>
</tr>
<tr class="even">
<td align="left">2018</td>
<td align="right">942.6</td>
</tr>
<tr class="odd">
<td align="left">2019</td>
<td align="right">167.0</td>
</tr>
</tbody>
</table>
<p>按年份平均一下，14年最多，看了3000多块钱的书。不得不说，看书真是一个极其便宜的消遣。</p>
</div>
<div class="section level3">
<h3>页数</h3>
<pre class="r"><code>book %&gt;% mutate(page = as.numeric(page)) %&gt;% 
  summarise(total = sum(page), avg = mean(page)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">total</th>
<th align="right">avg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">185511</td>
<td align="right">398.9484</td>
</tr>
</tbody>
</table>
<p>这些书一共十八万多页，平均每本数400页左右。</p>
<pre class="r"><code>book %&gt;% mutate(page = as.numeric(page)) %&gt;% 
  group_by(year) %&gt;% 
  summarise(total = sum(page)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">year</th>
<th align="right">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2011</td>
<td align="right">5059</td>
</tr>
<tr class="even">
<td align="left">2012</td>
<td align="right">26909</td>
</tr>
<tr class="odd">
<td align="left">2013</td>
<td align="right">25012</td>
</tr>
<tr class="even">
<td align="left">2014</td>
<td align="right">38407</td>
</tr>
<tr class="odd">
<td align="left">2015</td>
<td align="right">27053</td>
</tr>
<tr class="even">
<td align="left">2016</td>
<td align="right">35503</td>
</tr>
<tr class="odd">
<td align="left">2017</td>
<td align="right">17242</td>
</tr>
<tr class="even">
<td align="left">2018</td>
<td align="right">8144</td>
</tr>
<tr class="odd">
<td align="left">2019</td>
<td align="right">2182</td>
</tr>
</tbody>
</table>
<p>看的页数最多的一年也是14年，看了快四万页，平均起来，每天都要看100多页。</p>
</div>
<div class="section level3">
<h3>字数</h3>
<pre class="r"><code>book %&gt;% mutate(words = as.numeric(words)) %&gt;% 
  summarise(total = sum(words), avg = mean(words)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">total</th>
<th align="right">avg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">136291256</td>
<td align="right">293099.5</td>
</tr>
</tbody>
</table>
<p>字数是比较难统计的，所以进行了一些校正。除了前面提到的，我还进行了另外一步校正。如果书内标明了字数，那我就按书内的字数进行第一步校正，然后再乘以0.8；如果书内没有标明字数，我就随机找一页，算一算这一页大概有多少字，然后乘以总页数，这时得出的字数进行第一步校正，最后再乘以0.6。经过这样的校正之后，我这些年一共看了一亿三千六百万字的书，平均起来，每本书大概有三十万字。之前在Medium上看了一篇文章，作者讲怎样才能在一年之内看完200书，然后她把书定义为五万字。如果一本书只有五万字的话，那一年看200本真的没啥难的。我觉得还是把一本书定义为三十万字，可能更合适一点。</p>
<pre class="r"><code>book %&gt;% mutate(words = as.numeric(words)) %&gt;% 
  group_by(year) %&gt;% 
  summarise(total = sum(words)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">year</th>
<th align="right">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2011</td>
<td align="right">2531263</td>
</tr>
<tr class="even">
<td align="left">2012</td>
<td align="right">16750566</td>
</tr>
<tr class="odd">
<td align="left">2013</td>
<td align="right">15884629</td>
</tr>
<tr class="even">
<td align="left">2014</td>
<td align="right">28676764</td>
</tr>
<tr class="odd">
<td align="left">2015</td>
<td align="right">23470332</td>
</tr>
<tr class="even">
<td align="left">2016</td>
<td align="right">30016723</td>
</tr>
<tr class="odd">
<td align="left">2017</td>
<td align="right">11393177</td>
</tr>
<tr class="even">
<td align="left">2018</td>
<td align="right">5929402</td>
</tr>
<tr class="odd">
<td align="left">2019</td>
<td align="right">1638400</td>
</tr>
</tbody>
</table>
<p>按年份来看字数，最多的倒不是14年，而是16年了，可能那一年看了更多的大部头。</p>
<pre class="r"><code>book %&gt;% mutate(words = as.numeric(words)) %&gt;% 
  group_by(language) %&gt;% 
  summarise(total = sum(words)) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">language</th>
<th align="right">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">古汉</td>
<td align="right">20965668</td>
</tr>
<tr class="even">
<td align="left">古语</td>
<td align="right">11856219</td>
</tr>
<tr class="odd">
<td align="left">汉语</td>
<td align="right">82277559</td>
</tr>
<tr class="even">
<td align="left">英汉</td>
<td align="right">2162988</td>
</tr>
<tr class="odd">
<td align="left">英语</td>
<td align="right">19028822</td>
</tr>
</tbody>
</table>
<p>最后再按语言分类看一下，看得最多的自然是现代汉语的，但纯文言文和纯英文的书，我也看了及几百万字甚至上千万字（这里在把2除回去）。</p>
<p>我其实是reading for reading’s sake的，并没指望通过读书得到其他什么东西。给自己定一个量化的目标，而后每天按着计划执行一点，总不至于让自己陷入无所事事的境地。几年前，我给自己定的这个数量是3000，目前看来，虽然有难度，但也不是不可能完成的任务，所以，继续一页一页的看吧。</p>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="/tags/%E8%87%AA%E6%88%91%E5%88%86%E6%9E%90/">自我分析</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/03/r-basic-concept-and-operation/" data-tooltip="R的基本概念和操作">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/01/pseudo-dynamic-website-scraping/" data-tooltip="（伪）动态网页爬虫-《狗十三》豆瓣短评爬取">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/02/reading-records-analysis/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/02/reading-records-analysis/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/02/reading-records-analysis/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread"></div>
<script>





(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://rrtbmxl.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 孟祥良. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/03/r-basic-concept-and-operation/" data-tooltip="R的基本概念和操作">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/01/pseudo-dynamic-website-scraping/" data-tooltip="（伪）动态网页爬虫-《狗十三》豆瓣短评爬取">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/02/reading-records-analysis/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/02/reading-records-analysis/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/02/reading-records-analysis/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2019%2F02%2Freading-records-analysis%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2019%2F02%2Freading-records-analysis%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2019%2F02%2Freading-records-analysis%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">孟祥良</h4>
    
      <div id="about-card-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</div>
    
    
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/mlr-note-knn/">
                <h3 class="media-heading">《机器学习与R语言》学习笔记01：kNN</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">通过将《机器学习与R语言》一书中的代码tidyverse化，来学习这本书。
书中第一个例子是利用kNN算法来诊断乳腺癌。
首先载入需要用到的包：
library(tidyverse) # 清洗数据library(here) # 设置数据文件路径library(knitr) # 呈现更好看的表格library(kableExtra) # 同上library(class) # 使用包中的knn()函数library(gmodels) # 使用包中的CrossTable()函数然后导入数据并清洗：
wbcd &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;01-wisc_bc_data.csv&#39;)) %&gt;% select(-id) %&gt;% mutate(diagnosis = factor(diagnosis, levels = c(&#39;B&#39;, &#39;M&#39;),labels = c(&#39;Benign&#39;, &#39;Malignant&#39;))) %&gt;% mutate_if(is.numeric, ~ (.x - min(.x)) / (max(.x) - min(.x)))首先使用here函数找到数据文件的路径，然后使用read_csv函数将其读入R中；随后通过select函数将id变量去掉；然后利用mutate函数将diagnosis变量改为因子型；最后利用mutate_if函数，将所有数值型的变量进行min-max标准化，这里用到了公式化的匿名函数，可以使代码更为简练。此时的数据是这样的：
wbcd %&gt;% head() %&gt;% kable() %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, font_size = 12) %&gt;%scroll_box(width = &quot;100%&quot;) diagnosisradius_meantexture_meanperimeter_meanarea_meansmoothness_meancompactness_meanconcavity_meanconcave points_meansymmetry_meanfractal_dimension_meanradius_setexture_seperimeter_searea_sesmoothness_secompactness_seconcavity_seconcave points_sesymmetry_sefractal_dimension_seradius_worsttexture_worstperimeter_worstarea_worstsmoothness_worstcompactness_worstconcavity_worstconcave points_worstsymmetry_worstfractal_dimension_worstMalignant0.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/r-resources-collection/">
                <h3 class="media-heading">R语言学习资源总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ArticleConceptHistoryCommunicationBlogdownReportShinyWordMachine LearningBasicsClassificationClusteringDeep LearningDimensionality ReductionPredictionProgramEvaluationFunctionLoopPipeTutorialData AcquisitionOnlinebookTidyverseWebsiteVisualizationAdjustmentBasicCommon PlotsColorExtensionLine ChartMapScatter PlotTheory总结一下我自己看过的R语言学习资源，目前的分类还比较随意，因为很多内容都是交叉的，难以形成明确的体系。没啥特殊情况的话，每个周末都会补充新的内容。另外要强调一点，看教程虽然有助于学习，但真正能提升水平的，还是实践。如果工作中没有太多实践的机会的话，那也要自己想办法找些实践的机会。
还要吐槽一下，不论是tidyverse还是Rmarkdown，对中文的支持都不是很好，用中文标题生成的TOC无法跳转，所以我只好暂时把各部分的标题都写成英文了，以后有时间再琢磨这个问题。不过话说回来，确实是写成英文更方便点，因为我收藏夹里的文件夹名都是英文命名的，而这篇博客其实就是对我的收藏夹内容的总结。
Article收集了一些关于R的概念和历史的文章。
ConceptExplain R environments like I’m five (181110; 190307)
介绍什么是R语言的环境，非常简单易懂。
Environments in R (190128; 190408)</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/r-notebook-and-plan/">
                <h3 class="media-heading">R学习笔记及学习计划</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">人对事物的认识大概可以分为三个层次，从“未知的未知”到“已知的未知”再到“已知的已知”。如果确实是这样的话，那学习就可以分为两种，一种是把“未知的未知”变为“已知的未知”，如了解到这个世界上存在一种叫做“负数”的东西，但不知道它究竟指什么；另一种是把“已知的未知”变为“已知的已知”，如通过进一步的了解，获知“负数”的确切意义。德尔菲的神谕认为没有人比苏格拉底更聪明，其看重的可能并不在于苏格拉底是否比其他所有人拥有更多“已知的已知”，而是看到他比其他人拥有更多“已知的未知”。我不知道两种学习中哪一种更为重要，但我觉得，在大多数情况下，前一种学习都是后一种学习的先决条件。人的时间是有限的，没法把所有的知识都掌握，所以比较好的学习思路可能是先去获取足够多的“已知的未知”，再决定把哪些“已知的未知”转变为“已知的已知”。
我接触R已经三年多了，但真正开始学习R，也就一年多的样子。我对R本身其实没有多大的兴趣，但当我把tidyverse变为“已知的未知”时，才对这门语言产生了热情。翻开哲学的入门书，很有可能会发现最开始的章节是以苏格拉底来划分的，如类似“前苏格拉底时代的哲学家们”的说法。在这里，我也想用tidyverse这个词来对我的笔记章节进行划分（当然，tidyverse对应的哲学家更有可能是笛卡尔），具体来说，包括tidyverse之前，用来介绍R的一些基本知识；tidyverse之内，用来介绍tidyverse核心包的使用方法；tidyverse之上，用来介绍建立在tidyverse核心包基础上的一些实用的包；tidyverse之外，用来介绍与tidyverse无关，但很有用的一些包。当然，这些内容中的很大一部分对我来说还是“已知的未知”。
想弄这么个东西，目的主要有两个：一方面，把自己会的东西以教程的形式写出来，能让自己把“已知的已知”掌握得更牢固；另一方面，也能督促自己不断地去学习新知识，探索“未知的未知”，转化“已知的未知”。因此，内容方面，就包括我目前会的，和我将来想学的，具体内容可以看后面暂定的大纲。另外，我也给自己设定了几个要求：
术语尽量给出参考资料和对应的英文，不知道该如何翻译的直接用英文，符号给出对应的英文及其读音；
尽量保证所有的内容都能跟上R本体和所涉及的包的更新；
暂定的提纲如下：
tidyverse之前R的介绍及安装
R的基本概念及操作
R中的条件与循环
tidyveRse之内使用readr导入数据
使用rvest获取网络数据
dbplyr与数据库
dplyr包常用操作及管道操作符
tidyr包常用操作及tidy data
stringr包常用操作及正则表达式
forcats常用操作
lubridate常用操作
purrr包探索
组合使用
tidyverse代码风格
ggplot2基本统计图的绘制
ggplot2统计图的调整
ggplot2统计图的美化
tidyverse之上使用tidytext进行文本分析
使用ggvis绘制交互统计图
使用gganimate绘制动态统计图
tidyverse之外使用rmarkdown撰写报告
使用blogdown搭建博客
使用shiny制作网络应用</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/03/r-basic-concept-and-operation/">
                <h3 class="media-heading">R的基本概念和操作</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">R的基本操作a.计算b.逻辑运算c.赋值R的基本概念a.数据结构数据探索b.函数c.包190424
R的基本操作a.计算R可以作为计算器使用，+、-、*、/、^分别代表加减乘除和乘方：
2 ^ 2 / 2 - (2 * 2 + 2)## [1] -4%%求余数，%/%求商：
5 %% 2## [1] 15 %/% 2## [1] 2b.逻辑运算==、!=、&gt;、&gt;=、&lt;、&lt;=分别用来判断相等、不等、大于、大于等于、小于、小于等于的关系，符合逻辑返回TRUE，反之返回FALSE。对于部分字符（英文字母和汉字），似乎是字母顺序排在后面的更大；对于字符型数值，似乎与其数值型数值相等；另外，逻辑型数值中，TRUE等于1，而FALSE等于0：
TRUE == 1## [1] TRUEFALSE == 0## [1] TRUE&#39;白马&#39; != &#39;马&#39;## [1] TRUE1 == &#39;1&#39;## [1] TRUE&#39;x&#39; &lt; &#39;y&#39;## [1] TRUE&#39;一&#39; &gt; &#39;二&#39;## [1] TRUEc.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/02/reading-records-analysis/">
                <h3 class="media-heading">11年-19年读书记录分析</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/01/pseudo-dynamic-website-scraping/">
                <h3 class="media-heading">（伪）动态网页爬虫-《狗十三》豆瓣短评爬取</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jan 1, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/12/red-envelope/">
                <h3 class="media-heading">使用R语言模拟抢红包</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">有一次参加了一个特别无聊的讲座，实在是无事可做，就琢磨了一下像微信抢红包那样的机制是如何实现的。自己当时想了一个模拟的方式，出来的结果似乎也可以以假乱真。后来把相关的代码完善了下，用来在自己组织的R语言课上讲for循环和自编函数。现在把这些内容整理出来，权当作一篇小小的教程。
首先假设，有人发了一个200块钱的红包，分给10个人抢：
money &lt;- 200people &lt;- 10给每个人安排一个随机数：
set.seed(181209)rand_number &lt;- sample(1:10000, people, replace = TRUE)rand_number## [1] 4188 591 2386 4520 3692 979 8170 3728 7121 4408随后用每个随机数除以所有随机数的总和得到一个比值，乘以总钱数，进而得到每个人的钱数：
rand_money &lt;- rand_number/sum(rand_number)*moneyrand_money## [1] 21.054219 2.971118 11.995073 22.723274 18.560692 4.921700 41.072820## [8] 18.741674 35.799211 22.160219然后就可以知道具体每个人得到多少钱了：
paste0(paste0(sample(letters, 5, replace = TRUE), collapse = &#39;&#39;),&#39;得到了&#39;, round(rand_money[1], 2), &#39;元，红包剩余&#39;, round(money - sum(rand_money[1:1]), 2), &#39;元。&#39;)## [1] &quot;hdprm得到了21.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/ggplot2-collection/">
                <h3 class="media-heading">ggplot2及其扩展包绘图总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Bar PlotBox PlotHeatmapHistgramLine ChartMapPie ChartRadar ChartScatter PlotTreemap像这样的教程应该有很多了，但为了自己查阅起来方便，我决定自己也写一个。这里我会尽量多的用到各种theme和palette，省得每次绘图还要一个一个试，看哪个好看（通过这个过程，我可能体验到了女生出门前挑衣服的感觉）。
先把需要用到的包载入：
library(tidyverse)library(ggthemes)Bar Plot直条图应该是最常见的了，在心理学论文中用到直条图时，一般都是把自变量放到x轴上，因变量放到y轴上，然后再添加误差条：
iris %&gt;% group_by(Species) %&gt;% summarise(avg_sl = mean(Sepal.Length), se = sqrt(sd(Sepal.Length)/n())) %&gt;% ggplot(aes(Species, avg_sl, fill = Species)) + geom_col(width = .5) + geom_errorbar(aes(ymin = avg_sl - se, ymax = avg_sl + se),width = .3) + scale_y_continuous(expand = c(0, 0)) + scale_fill_brewer(palette = &#39;Set2&#39;) + labs(y = &#39;Sepal.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/text-analysis-for-tianlong/">
                <h3 class="media-heading">利用文本分析对比两版本天龙八部</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">今年三月份，为了掌握文本分析技术，特意找了两个版本《天龙八部》的txt文件作为数据而进行练习，但可能被其他事情给耽搁了，当时只完成了一部分。前几天金老去世，令人不胜感概，于是想把这个《天龙八部》的文本分析完成，也算是以自己的方式表达对大师的怀念。
首先还是载入相关的包，这次的包有点多：
library(tidyverse)library(readxl)library(tidytext)library(jiebaR)library(ggthemes)library(widyr)library(igraph)library(ggraph)然后将两个版本的小说文本导入，顺便导入了主要人物的人名，因为这次分析是以分析主要人物为主：
tl_new &lt;- read_lines(&#39;tl_new.txt&#39;)tl_old &lt;- read_lines(&#39;tl_old.txt&#39;)tl_main &lt;- read_lines(&#39;tl_main.txt&#39;) %&gt;% .[-1]因为每个人的称呼不止一个，如乔帮主、萧大王、姊夫等等，都是指萧峰一个人，所以为了统一人名，还要做一些替换工作：
tl_new_tran &lt;- tl_new %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)tl_old_tran &lt;- tl_old %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)上面的替换工作并不全，比如，同样是段郞，有时可能是指段誉，有时可能是指段正淳，这就需要具体的情境，才能判断出来这个词指的是谁，但这个工作太麻烦了，这里就放弃了。</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/rick-and-morty-heatmap/">
                <h3 class="media-heading">看图写代码：瑞克与莫蒂剧集评分热力图</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">大概是去年的这个时间，我在一个名叫Data Is Beautiful的reddit论坛上看到了一张Rick and Morty的分集评分热力图，就想用R把它重复出来。当时水平还不怎么样，只能画个大概出来，很多细节都不知道该如何呈现；前几个月，又重新尝试了下，大部分细节都知道该如何实现了，但还是差一点；这里再尝试一下，看看能不能完全重复出来，毕竟这张图应该就是用R画的。
图是这样的：
首先，还是先把需要用到的包载入：
library(tidyverse)然后载入数据：
rm &lt;- read_csv(&quot;rick &amp; morty.csv&quot;) %&gt;% mutate_at(vars(Episode, Season), as.factor)载入数据的时候，为方便后面的绘图，顺便把集数和季数两个变量改成了因子型。具体的数据是这样的：
rm## # A tibble: 31 x 3## Episode Season Rating## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;## 1 1 1 8.1## 2 2 1 8.7## 3 3 1 8.4## 4 4 1 8.6## 5 5 1 8.9## 6 6 1 9 ## 7 7 1 8.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         13 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/cover.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2019\/02\/reading-records-analysis\/';
          
            this.page.identifier = '\/2019\/02\/reading-records-analysis\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'rrtbmxl';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

