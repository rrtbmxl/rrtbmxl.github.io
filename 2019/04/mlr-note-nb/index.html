

  
    
  


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.54.0 with theme Tranquilpeak 0.4.3-BETA">
    <title>《机器学习与R语言》学习笔记02：朴素贝叶斯</title>
    <meta name="author" content="孟祥良">
    <meta name="keywords" content="">

    <link rel="icon" href="/favicon.png">
    

    
    <meta name="description" content="书中的第二个例子是利用朴素贝叶斯算法判断垃圾短信。
首先载入需要用到的包：
library(tidyverse) # 清洗数据library(here) # 设置数据文件路径library(tidytext) # 分词及创建稀疏矩阵library(e1071) # 建模library(gmodels) # 评估模型在清洗数据的时候遇到一定的困难，因为书中是用tm包进行文本处理的，而我完全没有用过这个包（甚至也没有装这个包），所以看书中的代码就只能凭感觉脑补了。不过，还好，最后还是成功写出了tidyverse化的数据清洗代码，如下：
sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% cast_sparse(row, word) %&gt;% as.matrix() %&gt;% as_tibble() %&gt;% select(which(colSums(.) &gt; 4)) %&gt;% bind_cols(read_csv(here(&#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;%select(-3) %&gt;% distinct()) %&gt;% mutate_if(is.">
    <meta property="og:description" content="书中的第二个例子是利用朴素贝叶斯算法判断垃圾短信。
首先载入需要用到的包：
library(tidyverse) # 清洗数据library(here) # 设置数据文件路径library(tidytext) # 分词及创建稀疏矩阵library(e1071) # 建模library(gmodels) # 评估模型在清洗数据的时候遇到一定的困难，因为书中是用tm包进行文本处理的，而我完全没有用过这个包（甚至也没有装这个包），所以看书中的代码就只能凭感觉脑补了。不过，还好，最后还是成功写出了tidyverse化的数据清洗代码，如下：
sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% cast_sparse(row, word) %&gt;% as.matrix() %&gt;% as_tibble() %&gt;% select(which(colSums(.) &gt; 4)) %&gt;% bind_cols(read_csv(here(&#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;%select(-3) %&gt;% distinct()) %&gt;% mutate_if(is.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="《机器学习与R语言》学习笔记02：朴素贝叶斯">
    <meta property="og:url" content="/2019/04/mlr-note-nb/">
    <meta property="og:site_name" content="RPG">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="RPG">
    <meta name="twitter:description" content="书中的第二个例子是利用朴素贝叶斯算法判断垃圾短信。
首先载入需要用到的包：
library(tidyverse) # 清洗数据library(here) # 设置数据文件路径library(tidytext) # 分词及创建稀疏矩阵library(e1071) # 建模library(gmodels) # 评估模型在清洗数据的时候遇到一定的困难，因为书中是用tm包进行文本处理的，而我完全没有用过这个包（甚至也没有装这个包），所以看书中的代码就只能凭感觉脑补了。不过，还好，最后还是成功写出了tidyverse化的数据清洗代码，如下：
sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% cast_sparse(row, word) %&gt;% as.matrix() %&gt;% as_tibble() %&gt;% select(which(colSums(.) &gt; 4)) %&gt;% bind_cols(read_csv(here(&#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;%select(-3) %&gt;% distinct()) %&gt;% mutate_if(is.">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=640">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">RPG</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">孟祥良</h4>
        
          <h5 class="sidebar-profile-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/rrtbmxl/rrtbmxl.github.io">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      《机器学习与R语言》学习笔记02：朴素贝叶斯
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-04-25T00:00:00Z">
        
  April 25, 2019

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              


<p>书中的第二个例子是利用朴素贝叶斯算法判断垃圾短信。</p>
<p>首先载入需要用到的包：</p>
<pre class="r"><code>library(tidyverse) # 清洗数据
library(here) # 设置数据文件路径
library(tidytext) # 分词及创建稀疏矩阵
library(e1071) # 建模
library(gmodels) # 评估模型</code></pre>
<p>在清洗数据的时候遇到一定的困难，因为书中是用<code>tm</code>包进行文本处理的，而我完全没有用过这个包（甚至也没有装这个包），所以看书中的代码就只能凭感觉脑补了。不过，还好，最后还是成功写出了<code>tidyverse</code>化的数据清洗代码，如下：</p>
<pre class="r"><code>sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
  mutate(type = factor(type),
         row = row_number()) %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;% 
  filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% 
  cast_sparse(row, word) %&gt;% 
  as.matrix() %&gt;% 
  as_tibble() %&gt;% 
  select(which(colSums(.) &gt; 4)) %&gt;% 
  bind_cols(read_csv(here(&#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
              mutate(type = factor(type),
                     row = row_number()) %&gt;% 
              unnest_tokens(word, text) %&gt;% 
              anti_join(stop_words) %&gt;% 
              filter(!str_detect(word, &#39;\\d&#39;)) %&gt;%
              select(-3) %&gt;% 
              distinct()) %&gt;% 
  mutate_if(is.numeric, factor, levels = c(0, 1), labels = c(&#39;No&#39;, &#39;Yes&#39;))</code></pre>
<p>虽然是很长一串，但还是要比书中的代码少10来行的，而且连贯性和可读性也更高，最重要的是，只需要命名一个变量。</p>
<p>分解一下：</p>
<p>原始数据是这样的：</p>
<pre class="r"><code>(sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)))</code></pre>
<pre><code>## # A tibble: 5,574 x 2
##    type  text                                                              
##    &lt;chr&gt; &lt;chr&gt;                                                             
##  1 ham   Go until jurong point, crazy.. Available only in bugis n great wo~
##  2 ham   Ok lar... Joking wif u oni...                                     
##  3 spam  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 200~
##  4 ham   U dun say so early hor... U c already then say...                 
##  5 ham   Nah I don&#39;t think he goes to usf, he lives around here though     
##  6 spam  FreeMsg Hey there darling it&#39;s been 3 week&#39;s now and no word back~
##  7 ham   Even my brother is not like to speak with me. They treat me like ~
##  8 ham   As per your request &#39;Melle Melle (Oru Minnaminunginte Nurungu Vet~
##  9 spam  WINNER!! As a valued network customer you have been selected to r~
## 10 spam  Had your mobile 11 months or more? U R entitled to Update to the ~
## # ... with 5,564 more rows</code></pre>
<p>随后将标签变量<code>type</code>变为因子型，并新增<code>row</code>变量，记录行数：</p>
<pre class="r"><code>sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
  mutate(type = factor(type),
         row = row_number())</code></pre>
<p>然后利用<code>tidytext</code>包中的<code>unnest_token</code>函数进行分词，利用<code>anti_join</code>函数去掉停用词，再利用<code>filter</code>和<code>str_detect</code>的组合去掉数字。此时的数据是这样的：</p>
<pre class="r"><code>(sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
  mutate(type = factor(type),
         row = row_number()) %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;% 
  filter(!str_detect(word, &#39;\\d&#39;)))</code></pre>
<pre><code>## # A tibble: 34,390 x 3
##    type    row word  
##    &lt;fct&gt; &lt;int&gt; &lt;chr&gt; 
##  1 ham       1 jurong
##  2 ham       1 crazy 
##  3 ham       1 bugis 
##  4 ham       1 world 
##  5 ham       1 la    
##  6 ham       1 buffet
##  7 ham       1 cine  
##  8 ham       1 amore 
##  9 ham       1 wat   
## 10 ham       2 lar   
## # ... with 34,380 more rows</code></pre>
<p>其中共涉及到7440个词汇。</p>
<p>这时遇到了困难，因为需要把数据整成稀疏矩阵，也就是要做到每个词自成一列，假如某条短信内出现了该词，则记为1，没有出现的话，则记为0。数据一共5000多行，而词汇共有7000多个，即要整理出一个5000*7000的矩阵或数据框。一开始想尝试用<code>tidyr</code>包来解决这个问题，结果发现生成了一个5GB的数据框，虽然也能把问题解决，但这个方法太慢了。看书里的方法，<code>tm</code>包中是有相关的函数来进行这一步转换的；去网上查，发现<code>Matrix</code>包也能解决这个问题，但它们都会破坏代码的完整性。后来想到，<code>tidytext</code>应该不会没有处理这种问题的函数，看了下，果然有个<code>cast_sparse</code>函数，可以调用<code>Matrix</code>包中的<code>sparseMatrix</code>函数。此时问题还没有完全解决，以为<code>cast_sparse</code>函数生成的矩阵是一个class为<code>dgCMatrix</code>的矩阵，没法直接转为数据框。又在网上查了下，发现可以先将其转为矩阵，然后再转为数据框。此时的部分数据是这样的：</p>
<pre class="r"><code>(sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
  mutate(type = factor(type),
         row = row_number()) %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;% 
  filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% 
  cast_sparse(row, word) %&gt;% 
  as.matrix() %&gt;% 
  as_tibble())</code></pre>
<pre><code>## # A tibble: 5,454 x 7,440
##    jurong crazy bugis world    la buffet  cine amore   wat   lar joking
##     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1      1     1     1     1     1      1     1     1     1     0      0
##  2      0     0     0     0     0      0     0     0     0     1      1
##  3      0     0     0     0     0      0     0     0     0     0      0
##  4      0     0     0     0     0      0     0     0     0     0      0
##  5      0     0     0     0     0      0     0     0     0     0      0
##  6      0     0     0     0     0      0     0     0     0     0      0
##  7      0     0     0     0     0      0     0     0     0     0      0
##  8      0     0     0     0     0      0     0     0     0     0      0
##  9      0     0     0     0     0      0     0     0     0     0      0
## 10      0     0     0     0     0      0     0     0     0     0      0
## # ... with 5,444 more rows, and 7,429 more variables: wif &lt;dbl&gt;,
## #   oni &lt;dbl&gt;, free &lt;dbl&gt;, entry &lt;dbl&gt;, wkly &lt;dbl&gt;, comp &lt;dbl&gt;, win &lt;dbl&gt;,
## #   fa &lt;dbl&gt;, cup &lt;dbl&gt;, final &lt;dbl&gt;, tkts &lt;dbl&gt;, text &lt;dbl&gt;,
## #   receive &lt;dbl&gt;, question &lt;dbl&gt;, std &lt;dbl&gt;, txt &lt;dbl&gt;, rate &lt;dbl&gt;,
## #   apply &lt;dbl&gt;, dun &lt;dbl&gt;, hor &lt;dbl&gt;, nah &lt;dbl&gt;, usf &lt;dbl&gt;, lives &lt;dbl&gt;,
## #   freemsg &lt;dbl&gt;, hey &lt;dbl&gt;, darling &lt;dbl&gt;, `week&#39;s` &lt;dbl&gt;, word &lt;dbl&gt;,
## #   fun &lt;dbl&gt;, tb &lt;dbl&gt;, xxx &lt;dbl&gt;, chgs &lt;dbl&gt;, send &lt;dbl&gt;, rcv &lt;dbl&gt;,
## #   brother &lt;dbl&gt;, speak &lt;dbl&gt;, treat &lt;dbl&gt;, aids &lt;dbl&gt;, patent &lt;dbl&gt;,
## #   request &lt;dbl&gt;, melle &lt;dbl&gt;, oru &lt;dbl&gt;, minnaminunginte &lt;dbl&gt;,
## #   nurungu &lt;dbl&gt;, vettam &lt;dbl&gt;, set &lt;dbl&gt;, callertune &lt;dbl&gt;,
## #   callers &lt;dbl&gt;, press &lt;dbl&gt;, copy &lt;dbl&gt;, friends &lt;dbl&gt;, winner &lt;dbl&gt;,
## #   valued &lt;dbl&gt;, network &lt;dbl&gt;, customer &lt;dbl&gt;, selected &lt;dbl&gt;,
## #   receivea &lt;dbl&gt;, prize &lt;dbl&gt;, reward &lt;dbl&gt;, claim &lt;dbl&gt;, call &lt;dbl&gt;,
## #   code &lt;dbl&gt;, valid &lt;dbl&gt;, hours &lt;dbl&gt;, mobile &lt;dbl&gt;, months &lt;dbl&gt;,
## #   entitled &lt;dbl&gt;, update &lt;dbl&gt;, colour &lt;dbl&gt;, mobiles &lt;dbl&gt;,
## #   camera &lt;dbl&gt;, gonna &lt;dbl&gt;, home &lt;dbl&gt;, talk &lt;dbl&gt;, stuff &lt;dbl&gt;,
## #   anymore &lt;dbl&gt;, tonight &lt;dbl&gt;, cried &lt;dbl&gt;, chances &lt;dbl&gt;, cash &lt;dbl&gt;,
## #   pounds &lt;dbl&gt;, cost &lt;dbl&gt;, day &lt;dbl&gt;, tsandcs &lt;dbl&gt;, reply &lt;dbl&gt;,
## #   hl &lt;dbl&gt;, info &lt;dbl&gt;, urgent &lt;dbl&gt;, won &lt;dbl&gt;, week &lt;dbl&gt;,
## #   membership &lt;dbl&gt;, jackpot &lt;dbl&gt;, www.dbuk.net &lt;dbl&gt;, lccltd &lt;dbl&gt;,
## #   pobox &lt;dbl&gt;, searching &lt;dbl&gt;, words &lt;dbl&gt;, breather &lt;dbl&gt;,
## #   promise &lt;dbl&gt;, wont &lt;dbl&gt;, ...</code></pre>
<p>下一步是按着书里的标准，去掉出现频次较低的词汇，仅保留至少出现过5次的词汇。这里也遇到点小困难，本来是想用<code>select_*</code>系列的函数剔除低频词汇的，但没有成功，最后在网上查到了更为简单的方式。这时变量就从7440变成了1312，数据框的大小也从300多MB减少到了50多MB：</p>
<pre class="r"><code>(sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
  mutate(type = factor(type),
         row = row_number()) %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;% 
  filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% 
  cast_sparse(row, word) %&gt;% 
  as.matrix() %&gt;% 
  as_tibble() %&gt;% 
  select(which(colSums(.) &gt; 4)))</code></pre>
<pre><code>## # A tibble: 5,454 x 1,312
##    crazy bugis world    la  cine   wat   lar joking   wif  free entry  wkly
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1     1     1     1     1     1     0      0     0     0     0     0
##  2     0     0     0     0     0     0     1      1     1     0     0     0
##  3     0     0     0     0     0     0     0      0     0     1     1     1
##  4     0     0     0     0     0     0     0      0     0     0     0     0
##  5     0     0     0     0     0     0     0      0     0     0     0     0
##  6     0     0     0     0     0     0     0      0     0     0     0     0
##  7     0     0     0     0     0     0     0      0     0     0     0     0
##  8     0     0     0     0     0     0     0      0     0     0     0     0
##  9     0     0     0     0     0     0     0      0     0     0     0     0
## 10     0     0     0     0     0     0     0      0     0     1     0     0
## # ... with 5,444 more rows, and 1,300 more variables: comp &lt;dbl&gt;,
## #   win &lt;dbl&gt;, cup &lt;dbl&gt;, final &lt;dbl&gt;, text &lt;dbl&gt;, receive &lt;dbl&gt;,
## #   question &lt;dbl&gt;, std &lt;dbl&gt;, txt &lt;dbl&gt;, rate &lt;dbl&gt;, apply &lt;dbl&gt;,
## #   dun &lt;dbl&gt;, nah &lt;dbl&gt;, usf &lt;dbl&gt;, freemsg &lt;dbl&gt;, hey &lt;dbl&gt;,
## #   darling &lt;dbl&gt;, word &lt;dbl&gt;, fun &lt;dbl&gt;, xxx &lt;dbl&gt;, send &lt;dbl&gt;,
## #   brother &lt;dbl&gt;, speak &lt;dbl&gt;, treat &lt;dbl&gt;, request &lt;dbl&gt;, set &lt;dbl&gt;,
## #   callertune &lt;dbl&gt;, callers &lt;dbl&gt;, press &lt;dbl&gt;, copy &lt;dbl&gt;,
## #   friends &lt;dbl&gt;, winner &lt;dbl&gt;, valued &lt;dbl&gt;, network &lt;dbl&gt;,
## #   customer &lt;dbl&gt;, selected &lt;dbl&gt;, prize &lt;dbl&gt;, reward &lt;dbl&gt;,
## #   claim &lt;dbl&gt;, call &lt;dbl&gt;, code &lt;dbl&gt;, valid &lt;dbl&gt;, hours &lt;dbl&gt;,
## #   mobile &lt;dbl&gt;, months &lt;dbl&gt;, entitled &lt;dbl&gt;, update &lt;dbl&gt;,
## #   colour &lt;dbl&gt;, mobiles &lt;dbl&gt;, camera &lt;dbl&gt;, gonna &lt;dbl&gt;, home &lt;dbl&gt;,
## #   talk &lt;dbl&gt;, stuff &lt;dbl&gt;, anymore &lt;dbl&gt;, tonight &lt;dbl&gt;, cash &lt;dbl&gt;,
## #   pounds &lt;dbl&gt;, cost &lt;dbl&gt;, day &lt;dbl&gt;, reply &lt;dbl&gt;, hl &lt;dbl&gt;,
## #   info &lt;dbl&gt;, urgent &lt;dbl&gt;, won &lt;dbl&gt;, week &lt;dbl&gt;, pobox &lt;dbl&gt;,
## #   searching &lt;dbl&gt;, words &lt;dbl&gt;, promise &lt;dbl&gt;, wont &lt;dbl&gt;,
## #   wonderful &lt;dbl&gt;, times &lt;dbl&gt;, date &lt;dbl&gt;, sunday &lt;dbl&gt;, credit &lt;dbl&gt;,
## #   click &lt;dbl&gt;, wap &lt;dbl&gt;, link &lt;dbl&gt;, message &lt;dbl&gt;, http &lt;dbl&gt;,
## #   watching &lt;dbl&gt;, eh &lt;dbl&gt;, remember &lt;dbl&gt;, naughty &lt;dbl&gt;, wet &lt;dbl&gt;,
## #   fine &lt;dbl&gt;, feel &lt;dbl&gt;, england &lt;dbl&gt;, dont &lt;dbl&gt;, miss &lt;dbl&gt;,
## #   team &lt;dbl&gt;, news &lt;dbl&gt;, ur &lt;dbl&gt;, national &lt;dbl&gt;, `i‘m` &lt;dbl&gt;,
## #   ha &lt;dbl&gt;, ü &lt;dbl&gt;, pay &lt;dbl&gt;, da &lt;dbl&gt;, ...</code></pre>
<p>这时一个稀疏矩阵就建好了，但数据中还没有标签，所以我又用一大段重复的代码把行数和标签并了进去。暂时没想到更简单的方式可以在不打断代码的前提下完成同样的事情。最后一步是按照书中讲到的，把所有预测变量变为因子型：</p>
<pre class="r"><code>sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
  mutate(type = factor(type),
         row = row_number()) %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words) %&gt;% 
  filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% 
  cast_sparse(row, word) %&gt;% 
  as.matrix() %&gt;% 
  as_tibble() %&gt;% 
  select(which(colSums(.) &gt; 4)) %&gt;% 
  bind_cols(read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% 
              mutate(type = factor(type),
                     row = row_number()) %&gt;% 
              unnest_tokens(word, text) %&gt;% 
              anti_join(stop_words) %&gt;% 
              filter(!str_detect(word, &#39;\\d&#39;)) %&gt;%
              select(-3) %&gt;% 
              distinct()) %&gt;% 
  mutate_if(is.numeric, factor, levels = c(0, 1), labels = c(&#39;No&#39;, &#39;Yes&#39;))</code></pre>
<p>数据已经清洗好了，可以创建训练数据集和测试数据集了：</p>
<pre class="r"><code>set.seed(0424)
sms_train &lt;- sms %&gt;% sample_n(4169)
sms_test &lt;- sms %&gt;% setdiff(sms_train)</code></pre>
<p>这里也遇到个问题。在去掉频次较少的词汇前，也就是有7000多列时，<code>sample_n</code>函数会报错，但去掉那些词汇后，就没有问题了。猜测使用<code>sample_n</code>函数时，数据的变量数不能大于参数n的值？</p>
<p>然后就可以建模了。模型里的训练数据去掉了最后两列（行数和标签），而且需要注意的是，因为词汇中包括type这个词，所以本来的<code>type</code>变量名被自动变更为<code>type1</code>了。</p>
<pre class="r"><code>sms_class &lt;- naiveBayes(sms_train[, -1313:-1314], sms_train$type1)
sms_pred &lt;- predict(sms_class, sms_test)</code></pre>
<p>用测试数据评估一下模型：</p>
<pre class="r"><code>CrossTable(sms_pred, sms_test$type1, 
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c(&#39;predicted&#39;, &#39;actual&#39;))</code></pre>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |           N / Row Total |
## |           N / Col Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  890 
## 
##  
##              | actual 
##    predicted |       ham |      spam | Row Total | 
## -------------|-----------|-----------|-----------|
##          ham |       789 |        14 |       803 | 
##              |     0.983 |     0.017 |     0.902 | 
##              |     0.996 |     0.143 |           | 
## -------------|-----------|-----------|-----------|
##         spam |         3 |        84 |        87 | 
##              |     0.034 |     0.966 |     0.098 | 
##              |     0.004 |     0.857 |           | 
## -------------|-----------|-----------|-----------|
## Column Total |       792 |        98 |       890 | 
##              |     0.890 |     0.110 |           | 
## -------------|-----------|-----------|-----------|
## 
## </code></pre>
<p>应该还挺不错的。</p>
<p>按书里的方式，更改<code>laplace</code>参数再试一下：</p>
<pre class="r"><code>sms_class1 &lt;- naiveBayes(sms_train[, -1313:-1314], sms_train$type1, laplace = 1)
sms_pred1 &lt;- predict(sms_class1, sms_test)

CrossTable(sms_pred1, sms_test$type1, 
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c(&#39;predicted&#39;, &#39;actual&#39;))</code></pre>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |           N / Row Total |
## |           N / Col Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  890 
## 
##  
##              | actual 
##    predicted |       ham |      spam | Row Total | 
## -------------|-----------|-----------|-----------|
##          ham |       790 |        16 |       806 | 
##              |     0.980 |     0.020 |     0.906 | 
##              |     0.997 |     0.163 |           | 
## -------------|-----------|-----------|-----------|
##         spam |         2 |        82 |        84 | 
##              |     0.024 |     0.976 |     0.094 | 
##              |     0.003 |     0.837 |           | 
## -------------|-----------|-----------|-----------|
## Column Total |       792 |        98 |       890 | 
##              |     0.890 |     0.110 |           | 
## -------------|-----------|-----------|-----------|
## 
## </code></pre>
<p>此时模型确实得到了一定程度的优化，因为虽然多看了两条垃圾短信，但少错过了一条非垃圾短信。</p>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="/tags/%E7%AC%94%E8%AE%B0/">笔记</a>

  <a class="tag tag--primary tag--small" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/05/anime-recommend-with-ml/" data-tooltip="使用机器学习给自己推荐番剧：first try">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/04/mlr-note-knn/" data-tooltip="《机器学习与R语言》学习笔记01：kNN">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/04/mlr-note-nb/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/04/mlr-note-nb/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/04/mlr-note-nb/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread"></div>
<script>





(function() { 
var d = document, s = d.createElement('script');
s.src = 'https://rrtbmxl.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 孟祥良. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/05/anime-recommend-with-ml/" data-tooltip="使用机器学习给自己推荐番剧：first try">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/04/mlr-note-knn/" data-tooltip="《机器学习与R语言》学习笔记01：kNN">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/04/mlr-note-nb/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/04/mlr-note-nb/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/04/mlr-note-nb/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2019%2F04%2Fmlr-note-nb%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2019%2F04%2Fmlr-note-nb%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2019%2F04%2Fmlr-note-nb%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">孟祥良</h4>
    
      <div id="about-card-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</div>
    
    
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/05/anime-recommend-with-ml/">
                <h3 class="media-heading">使用机器学习给自己推荐番剧：first try</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">A.关于数据B.数据探索b1.番名b2.季数b3.集数b4.年份b5.季节b6.来源b7.类别b8.制作公司b9.评分及人数extra 1.个人、豆瓣与MAL的对比b0.声优extra 2.声优关系网络C.建模与评估c1.清洗数据c2.创建训练数据集和测试数据集c3.朴素贝叶斯算法c4.规则学习算法D.局限于展望花费许多时间学到的东西自然是要用一用的，如果工作中用不到的话，那就用来为生活增添些许乐趣吧。
看番多年，难免遇到烂番，既浪费时间，又影响心情；另外，有些优秀的番剧，可能因为某些原因，与自己失之交臂。要是能在自己看过的番剧的基础上，建立一个模型，帮自己避免烂番，发掘好番，那真是再好不过了。于是我就把自己近年来看过的番剧整理了一下，收集了若干相关信息，做成了excel表格，作为建立模型的原材料。数据是手动整理的，花费的时间比我预计的多很多，但在整理的过程中，也引发了不少回忆，所以也算不上是浪费时间。
A.关于数据数据就是我看番的记录，不全，但应该是足够用了。反应变量是我对某番剧的评分，从5分到10分，是离散数据，在这第一次尝试中，计划将其变为二元分类数据，即5分到7分为不推荐，8分到10分为推荐。预测变量有十来个，包括番剧的年代、类型、制作公司、声优和网站评分等信息，在第一次尝试中，计划把数据弄成稀疏矩阵，使用朴素贝叶斯算法和规则学习算法来进行分类。
在查看数据之前，先载入分析需要用到的包：
library(tidyverse)library(readxl)library(here)library(ggthemes)library(corrplot)library(tidytext)library(widyr)library(igraph)library(ggraph)library(e1071)library(RWeka)library(gmodels)然后导入数据，并进行初步的清洗：
anime &lt;- read_xlsx(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;anime_record.xlsx&#39;)) %&gt;%mutate_all(str_remove_all, pattern = &#39;\U00A0&#39;) %&gt;% # 去掉不间断空格&lt;U+00A0&gt;select(-record_time) %&gt;%mutate(studio = str_remove(studio, &#39;,.*&#39;)) %&gt;%mutate_at(vars(c(&#39;season_number&#39;, &#39;episode&#39;, &#39;year&#39;, &#39;rating&#39;, &#39;db_number&#39;, &#39;mal_number&#39;)), as.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/mlr-note-nb/">
                <h3 class="media-heading">《机器学习与R语言》学习笔记02：朴素贝叶斯</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">书中的第二个例子是利用朴素贝叶斯算法判断垃圾短信。
首先载入需要用到的包：
library(tidyverse) # 清洗数据library(here) # 设置数据文件路径library(tidytext) # 分词及创建稀疏矩阵library(e1071) # 建模library(gmodels) # 评估模型在清洗数据的时候遇到一定的困难，因为书中是用tm包进行文本处理的，而我完全没有用过这个包（甚至也没有装这个包），所以看书中的代码就只能凭感觉脑补了。不过，还好，最后还是成功写出了tidyverse化的数据清洗代码，如下：
sms &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;% cast_sparse(row, word) %&gt;% as.matrix() %&gt;% as_tibble() %&gt;% select(which(colSums(.) &gt; 4)) %&gt;% bind_cols(read_csv(here(&#39;data&#39;, &#39;02-sms_spam.csv&#39;)) %&gt;% mutate(type = factor(type),row = row_number()) %&gt;% unnest_tokens(word, text) %&gt;% anti_join(stop_words) %&gt;% filter(!str_detect(word, &#39;\\d&#39;)) %&gt;%select(-3) %&gt;% distinct()) %&gt;% mutate_if(is.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/mlr-note-knn/">
                <h3 class="media-heading">《机器学习与R语言》学习笔记01：kNN</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">通过将《机器学习与R语言》一书中的代码tidyverse化，来学习这本书。
书中第一个例子是利用kNN算法来诊断乳腺癌。
首先载入需要用到的包：
library(tidyverse) # 清洗数据library(here) # 设置数据文件路径library(knitr) # 呈现更好看的表格library(kableExtra) # 同上library(class) # 使用包中的knn()函数library(gmodels) # 使用包中的CrossTable()函数然后导入数据并清洗：
wbcd &lt;- read_csv(here(&#39;content&#39;, &#39;post&#39;, &#39;data&#39;, &#39;01-wisc_bc_data.csv&#39;)) %&gt;% select(-id) %&gt;% mutate(diagnosis = factor(diagnosis, levels = c(&#39;B&#39;, &#39;M&#39;),labels = c(&#39;Benign&#39;, &#39;Malignant&#39;))) %&gt;% mutate_if(is.numeric, ~ (.x - min(.x)) / (max(.x) - min(.x)))首先使用here函数找到数据文件的路径，然后使用read_csv函数将其读入R中；随后通过select函数将id变量去掉；然后利用mutate函数将diagnosis变量改为因子型；最后利用mutate_if函数，将所有数值型的变量进行min-max标准化，这里用到了公式化的匿名函数，可以使代码更为简练。此时的数据是这样的：
wbcd %&gt;% head() %&gt;% kable() %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, font_size = 12) %&gt;%scroll_box(width = &quot;100%&quot;) diagnosisradius_meantexture_meanperimeter_meanarea_meansmoothness_meancompactness_meanconcavity_meanconcave points_meansymmetry_meanfractal_dimension_meanradius_setexture_seperimeter_searea_sesmoothness_secompactness_seconcavity_seconcave points_sesymmetry_sefractal_dimension_seradius_worsttexture_worstperimeter_worstarea_worstsmoothness_worstcompactness_worstconcavity_worstconcave points_worstsymmetry_worstfractal_dimension_worstMalignant0.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/r-resources-collection/">
                <h3 class="media-heading">R语言学习资源总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ArticleConceptHistoryCommunicationBlogdownReportShinyWordMachine LearningBasicsClassificationClusteringDeep LearningDimensionality ReductionPredictionProgramEvaluationFunctionLoopPipeTutorialData AcquisitionOnlinebookTidyverseWebsiteVisualizationAdjustmentBasicCommon PlotsColorExtensionLine ChartMapScatter PlotTheory总结一下我自己看过的R语言学习资源，目前的分类还比较随意，因为很多内容都是交叉的，难以形成明确的体系。没啥特殊情况的话，每个周末都会补充新的内容。另外要强调一点，看教程虽然有助于学习，但真正能提升水平的，还是实践。如果工作中没有太多实践的机会的话，那也要自己想办法找些实践的机会。
还要吐槽一下，不论是tidyverse还是Rmarkdown，对中文的支持都不是很好，用中文标题生成的TOC无法跳转，所以我只好暂时把各部分的标题都写成英文了，以后有时间再琢磨这个问题。不过话说回来，确实是写成英文更方便点，因为我收藏夹里的文件夹名都是英文命名的，而这篇博客其实就是对我的收藏夹内容的总结。
Article收集了一些关于R的概念和历史的文章。
ConceptExplain R environments like I’m five (181110; 190307)
介绍什么是R语言的环境，非常简单易懂。
Environments in R (190128; 190408)</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/r-notebook-and-plan/">
                <h3 class="media-heading">R学习笔记及学习计划</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">人对事物的认识大概可以分为三个层次，从“未知的未知”到“已知的未知”再到“已知的已知”。如果确实是这样的话，那学习就可以分为两种，一种是把“未知的未知”变为“已知的未知”，如了解到这个世界上存在一种叫做“负数”的东西，但不知道它究竟指什么；另一种是把“已知的未知”变为“已知的已知”，如通过进一步的了解，获知“负数”的确切意义。德尔菲的神谕认为没有人比苏格拉底更聪明，其看重的可能并不在于苏格拉底是否比其他所有人拥有更多“已知的已知”，而是看到他比其他人拥有更多“已知的未知”。我不知道两种学习中哪一种更为重要，但我觉得，在大多数情况下，前一种学习都是后一种学习的先决条件。人的时间是有限的，没法把所有的知识都掌握，所以比较好的学习思路可能是先去获取足够多的“已知的未知”，再决定把哪些“已知的未知”转变为“已知的已知”。
我接触R已经三年多了，但真正开始学习R，也就一年多的样子。我对R本身其实没有多大的兴趣，但当我把tidyverse变为“已知的未知”时，才对这门语言产生了热情。翻开哲学的入门书，很有可能会发现最开始的章节是以苏格拉底来划分的，如类似“前苏格拉底时代的哲学家们”的说法。在这里，我也想用tidyverse这个词来对我的笔记章节进行划分（当然，tidyverse对应的哲学家更有可能是笛卡尔），具体来说，包括tidyverse之前，用来介绍R的一些基本知识；tidyverse之内，用来介绍tidyverse核心包的使用方法；tidyverse之上，用来介绍建立在tidyverse核心包基础上的一些实用的包；tidyverse之外，用来介绍与tidyverse无关，但很有用的一些包。当然，这些内容中的很大一部分对我来说还是“已知的未知”。
想弄这么个东西，目的主要有两个：一方面，把自己会的东西以教程的形式写出来，能让自己把“已知的已知”掌握得更牢固；另一方面，也能督促自己不断地去学习新知识，探索“未知的未知”，转化“已知的未知”。因此，内容方面，就包括我目前会的，和我将来想学的，具体内容可以看后面暂定的大纲。另外，我也给自己设定了几个要求：
术语尽量给出参考资料和对应的英文，不知道该如何翻译的直接用英文，符号给出对应的英文及其读音；
尽量保证所有的内容都能跟上R本体和所涉及的包的更新；
暂定的提纲如下：
tidyverse之前R的介绍及安装
R的基本概念及操作
R中的条件与循环
tidyveRse之内使用readr导入数据
使用rvest获取网络数据
dbplyr与数据库
dplyr包常用操作及管道操作符
tidyr包常用操作及tidy data
stringr包常用操作及正则表达式
forcats常用操作
lubridate常用操作
purrr包探索
组合使用
tidyverse代码风格
ggplot2基本统计图的绘制
ggplot2统计图的调整
ggplot2统计图的美化
tidyverse之上使用tidytext进行文本分析
使用ggvis绘制交互统计图
使用gganimate绘制动态统计图
tidyverse之外使用rmarkdown撰写报告
使用blogdown搭建博客
使用shiny制作网络应用</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/03/r-basic-concept-and-operation/">
                <h3 class="media-heading">R的基本概念和操作</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">R的基本操作a.计算b.逻辑运算c.赋值R的基本概念a.数据结构数据探索b.函数c.包190424
R的基本操作a.计算R可以作为计算器使用，+、-、*、/、^分别代表加减乘除和乘方：
2 ^ 2 / 2 - (2 * 2 + 2)## [1] -4%%求余数，%/%求商：
5 %% 2## [1] 15 %/% 2## [1] 2b.逻辑运算==、!=、&gt;、&gt;=、&lt;、&lt;=分别用来判断相等、不等、大于、大于等于、小于、小于等于的关系，符合逻辑返回TRUE，反之返回FALSE。对于部分字符（英文字母和汉字），似乎是字母顺序排在后面的更大；对于字符型数值，似乎与其数值型数值相等；另外，逻辑型数值中，TRUE等于1，而FALSE等于0：
TRUE == 1## [1] TRUEFALSE == 0## [1] TRUE&#39;白马&#39; != &#39;马&#39;## [1] TRUE1 == &#39;1&#39;## [1] TRUE&#39;x&#39; &lt; &#39;y&#39;## [1] TRUE&#39;一&#39; &gt; &#39;二&#39;## [1] TRUEc.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/02/reading-records-analysis/">
                <h3 class="media-heading">11年-19年读书记录分析</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/01/pseudo-dynamic-website-scraping/">
                <h3 class="media-heading">（伪）动态网页爬虫-《狗十三》豆瓣短评爬取</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jan 1, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/12/red-envelope/">
                <h3 class="media-heading">使用R语言模拟抢红包</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">有一次参加了一个特别无聊的讲座，实在是无事可做，就琢磨了一下像微信抢红包那样的机制是如何实现的。自己当时想了一个模拟的方式，出来的结果似乎也可以以假乱真。后来把相关的代码完善了下，用来在自己组织的R语言课上讲for循环和自编函数。现在把这些内容整理出来，权当作一篇小小的教程。
首先假设，有人发了一个200块钱的红包，分给10个人抢：
money &lt;- 200people &lt;- 10给每个人安排一个随机数：
set.seed(181209)rand_number &lt;- sample(1:10000, people, replace = TRUE)rand_number## [1] 4188 591 2386 4520 3692 979 8170 3728 7121 4408随后用每个随机数除以所有随机数的总和得到一个比值，乘以总钱数，进而得到每个人的钱数：
rand_money &lt;- rand_number/sum(rand_number)*moneyrand_money## [1] 21.054219 2.971118 11.995073 22.723274 18.560692 4.921700 41.072820## [8] 18.741674 35.799211 22.160219然后就可以知道具体每个人得到多少钱了：
paste0(paste0(sample(letters, 5, replace = TRUE), collapse = &#39;&#39;),&#39;得到了&#39;, round(rand_money[1], 2), &#39;元，红包剩余&#39;, round(money - sum(rand_money[1:1]), 2), &#39;元。&#39;)## [1] &quot;hdprm得到了21.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/ggplot2-collection/">
                <h3 class="media-heading">ggplot2及其扩展包绘图总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Bar PlotBox PlotHeatmapHistgramLine ChartMapPie ChartRadar ChartScatter PlotTreemap像这样的教程应该有很多了，但为了自己查阅起来方便，我决定自己也写一个。这里我会尽量多的用到各种theme和palette，省得每次绘图还要一个一个试，看哪个好看（通过这个过程，我可能体验到了女生出门前挑衣服的感觉）。
先把需要用到的包载入：
library(tidyverse)library(ggthemes)Bar Plot直条图应该是最常见的了，在心理学论文中用到直条图时，一般都是把自变量放到x轴上，因变量放到y轴上，然后再添加误差条：
iris %&gt;% group_by(Species) %&gt;% summarise(avg_sl = mean(Sepal.Length), se = sqrt(sd(Sepal.Length)/n())) %&gt;% ggplot(aes(Species, avg_sl, fill = Species)) + geom_col(width = .5) + geom_errorbar(aes(ymin = avg_sl - se, ymax = avg_sl + se),width = .3) + scale_y_continuous(expand = c(0, 0)) + scale_fill_brewer(palette = &#39;Set2&#39;) + labs(y = &#39;Sepal.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         15 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/cover.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2019\/04\/mlr-note-nb\/';
          
            this.page.identifier = '\/2019\/04\/mlr-note-nb\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'rrtbmxl';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

