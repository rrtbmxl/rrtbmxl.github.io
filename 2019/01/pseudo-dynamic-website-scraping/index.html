

  
    
  


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.54.0 with theme Tranquilpeak 0.4.3-BETA">
    <title>（伪）动态网页爬虫-《狗十三》豆瓣短评爬取</title>
    <meta name="author" content="孟祥良">
    <meta name="keywords" content="">

    <link rel="icon" href="/favicon.png">
    

    
    <meta name="description" content="这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.">
    <meta property="og:description" content="这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="（伪）动态网页爬虫-《狗十三》豆瓣短评爬取">
    <meta property="og:url" content="/2019/01/pseudo-dynamic-website-scraping/">
    <meta property="og:site_name" content="RPG">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="RPG">
    <meta name="twitter:description" content="这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=640">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">RPG</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">孟祥良</h4>
        
          <h5 class="sidebar-profile-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/rrtbmxl/rrtbmxl.github.io">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      （伪）动态网页爬虫-《狗十三》豆瓣短评爬取
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-01-06T00:00:00Z">
        
  January 6, 2019

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<link href="/rmarkdown-libs/wordcloud2/wordcloud.css" rel="stylesheet" />
<script src="/rmarkdown-libs/wordcloud2/wordcloud2-all.js"></script>
<script src="/rmarkdown-libs/wordcloud2/hover.js"></script>
<script src="/rmarkdown-libs/wordcloud2-binding/wordcloud2.js"></script>


<p>这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去<a href="https://movie.douban.com/subject/25716096/comments?start=0&amp;sort=new_score&amp;status=P&amp;percent_type=">豆瓣</a>上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击<strong>后页</strong>，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用<code>rvest</code>包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下<a href="https://stackoverflow.com/questions/28418770/using-rvest-or-httr-to-log-in-to-non-standard-forms-on-a-webpage">模拟登录</a>的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用<code>RSelenium</code>爬取动态网页，这里我完全可以先用<code>RSelenium</code>模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。</p>
<p>首先还是载入需要用的包，要使用<code>RSelenium</code>包，还要先进行一些配置，具体内容可以看<code>RSelenium</code>包的<a href="http://ropensci.github.io/RSelenium/articles/basics.html">官方网站</a>（这网站好像需要科学上网）：</p>
<pre class="r"><code>library(tidyverse)
library(RSelenium)
library(rvest)
library(jiebaR)
library(wordcloud2)
library(knitr)</code></pre>
<p>接下来跟<strong>Selenium Server</strong>进行连接，这里我用的是<strong>Chrome</strong>浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：</p>
<pre class="r"><code> rd &lt;- remoteDriver(
   remoteServerAddr = &quot;localhost&quot;,
   port = 4444L,
   browserName = &quot;chrome&quot;
)</code></pre>
<p>然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：</p>
<pre class="r"><code>rd$open()
rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)

we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)
we$sendKeysToElement(list(&#39;用户名&#39;))

we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)
we$sendKeysToElement(list(&#39;密码&#39;))

we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)
we$clickElement()</code></pre>
<p>如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。<code>RSelenium</code>包中的函数名就明白显示了它是干什么的，而参数中的那些<strong>xpath</strong>，在<strong>Chrome</strong>浏览器中都是可以直接复制出来的。</p>
<p>后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的<strong>xpath</strong>，所以那部分用了一些<code>if</code>条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。</p>
<pre class="r"><code>rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)

dog13 &lt;- tibble()
for (i in 1:50) {
  
  rank &lt;- character(0)
  time &lt;- character(0)
  help &lt;- character(0)
  text &lt;- character(0)
  temp &lt;- tibble()
  
  for (j in 1:20) {
    
    xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)
    we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)
    rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, 
                      &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())
    
    if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {
      
      xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)
      we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)
      time[j] &lt;- we$getElementText() %&gt;% unlist()
      
    } else {
      
      xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)
      we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)
      time[j] &lt;- we$getElementText() %&gt;% unlist()
      
    }
    
    xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)
    we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)
    help[j] &lt;- we$getElementText() %&gt;% unlist()
    
    xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)
    we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)
    text[j] &lt;- we$getElementText() %&gt;% unlist()
    
    df &lt;- tibble(rank, time, help, text)
    
  }
  
  dog13 &lt;- bind_rows(dog13, df)
  
  rest &lt;- sample(1:10, 1)
  
  if (i &lt; 2) {
    
    we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)
    we$clickElement()
    Sys.sleep(rest)
    
  } else {
    
    we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a[3]&#39;)
    we$clickElement()
    Sys.sleep(rest)
    
  }
  
}</code></pre>
<p>到这里，需要的内容就爬取完毕了，不过，既然已经爬到了，还是简单分析一下吧。进行分析前，先简单处理一下：</p>
<pre class="r"><code>dog13 &lt;- read.csv(&#39;dog13.csv&#39;, stringsAsFactors = FALSE) %&gt;% 
  mutate(score = case_when(rank == &#39;力荐&#39; ~ 5, rank == &#39;推荐&#39; ~ 4,
                           rank == &#39;还行&#39; ~ 3, rank == &#39;较差&#39; ~ 2,
                           rank == &#39;很差&#39; ~ 1) %&gt;% as.integer(),
         year = str_sub(time, 1, 4) %&gt;% as.integer())</code></pre>
<p>现在的数据是这样的：</p>
<pre class="r"><code>dog13 %&gt;% head() %&gt;% kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">rank</th>
<th align="left">time</th>
<th align="right">help</th>
<th align="left">text</th>
<th align="right">score</th>
<th align="right">year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">力荐</td>
<td align="left">2018-01-28</td>
<td align="right">11204</td>
<td align="left">“你看，这个孩子好懂事啊。”“你怎么知道她是不是害怕、沉默、妥协呢？”</td>
<td align="right">5</td>
<td align="right">2018</td>
</tr>
<tr class="even">
<td align="left">力荐</td>
<td align="left">2016-09-02</td>
<td align="right">8650</td>
<td align="left">原来我们都是这样长大的……或者说，如果没有共鸣，你知不知道你有多幸运……</td>
<td align="right">5</td>
<td align="right">2016</td>
</tr>
<tr class="odd">
<td align="left">力荐</td>
<td align="left">2014-02-19</td>
<td align="right">4540</td>
<td align="left">我之所以坚决认为不该要孩子，没有别的原因，仅仅是因为我实在没有把握让一个充满灵气的生命不被“成长”为一个认为《时间简史》只是给孩子看的、用一个谎言去圆另一个谎言的大人。PS：这应该就是今年你能看到的最好的华语电影</td>
<td align="right">5</td>
<td align="right">2014</td>
</tr>
<tr class="even">
<td align="left">还行</td>
<td align="left">2013-10-16</td>
<td align="right">4335</td>
<td align="left">狗是引题，13是成长，狗B是伪善的成人世界。家长不知教育孩子的根本，而拿狗出气，这就是中国式教育的最大问题。新狗代替老狗去死，女孩意识到狗狗回来受罪不如在外人那好吃好伺候着，这是她向成人世界的妥协也是她逐渐迈向成人的成长。</td>
<td align="right">3</td>
<td align="right">2013</td>
</tr>
<tr class="odd">
<td align="left">力荐</td>
<td align="left">2018-02-21</td>
<td align="right">3896</td>
<td align="left">李玩的名字是胡乱取的，弟弟的名字是认真取的，因为“男孩的名字不能太随便了”。 继母随便找只狗来敷衍李玩，爸爸还强迫她承认这就是爱因斯坦。 是继母买来了新狗，也是继母要把新狗卖了。狗只是畜生，利用完了就可以扔了。 李玩推倒了爷爷，遭到了爸爸的暴打；弟弟打了奶奶，爸爸却反过来哄弟弟。 弟弟挑衅新狗在先，爸爸却去打新狗。 李玩永远是错的，弟弟永远是对的。 于是，李玩变得“成熟懂事”了，她会不让爸爸难堪，忍痛吃狗肉；她会为了不让爱因斯坦跟她受苦，忍痛离开。 但我还是想念最真实的她，希望她能做回自己。 我们人人都是李玩，被生活磨平了棱角，失去了个性，扔掉了脾气，忘记了初心，还美其名曰“这就是成长”。 我们“提高了”情商，“学会了”做违心的事，说违心的话，再也不遵循自己的内心。 狗永远是狗，人有时却不是人。</td>
<td align="right">5</td>
<td align="right">2018</td>
</tr>
<tr class="even">
<td align="left">推荐</td>
<td align="left">2018-12-02</td>
<td align="right">3016</td>
<td align="left">这毕竟还是大城市的较为体面的家庭的故事了，女孩要在父亲面前挑衅地吹啤酒瓶才会挨一顿打，打完还能得到道歉与补偿。在我们十八线小城市的版本里，女孩准备出门找狗的时候就已经可以赢得两记耳光了，没有发出尖叫的机会，没有摔门摔碗的机会，只能把头深深地埋进被窝里无声哭一场，第二天起来，就长大了。</td>
<td align="right">4</td>
<td align="right">2018</td>
</tr>
</tbody>
</table>
<p>看看愿意花时间写短评的人们对该片的评分：</p>
<pre class="r"><code>mean(dog13$score, na.rm = TRUE) %&gt;% round(1) * 2</code></pre>
<pre><code>## [1] 7.6</code></pre>
<p>比主页面上的8.2分好像低不少的。</p>
<p>看看评分随时间的变化：</p>
<pre class="r"><code>dog13 %&gt;% group_by(year) %&gt;% 
  summarise(n = n(), 
            score = mean(score, na.rm = TRUE) %&gt;% round(1) * 2) %&gt;% 
  select(年份 = 1, 评价数 = 2, 分数 = 3) %&gt;% 
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="center">年份</th>
<th align="center">评价数</th>
<th align="center">分数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">2013</td>
<td align="center">35</td>
<td align="center">7.8</td>
</tr>
<tr class="even">
<td align="center">2014</td>
<td align="center">17</td>
<td align="center">8.2</td>
</tr>
<tr class="odd">
<td align="center">2015</td>
<td align="center">6</td>
<td align="center">8.4</td>
</tr>
<tr class="even">
<td align="center">2016</td>
<td align="center">26</td>
<td align="center">8.0</td>
</tr>
<tr class="odd">
<td align="center">2017</td>
<td align="center">6</td>
<td align="center">7.6</td>
</tr>
<tr class="even">
<td align="center">2018</td>
<td align="center">408</td>
<td align="center">7.6</td>
</tr>
<tr class="odd">
<td align="center">2019</td>
<td align="center">2</td>
<td align="center">6.0</td>
</tr>
</tbody>
</table>
<p>评分随时间先增后减，短评主要集中在解禁后的18年。</p>
<p>最后画个词云吧：</p>
<pre class="r"><code>worker &lt;- worker(stop_word = &#39;stopwords_cn.txt&#39;)

dog13_overall &lt;- str_c(dog13$text, collapse = &#39;&#39;)

dog13_word_overall &lt;- worker[dog13_overall]

dog13_word_overall_freq &lt;- dog13_word_overall %&gt;% 
  table() %&gt;% 
  as.tibble() %&gt;% 
  select(word = 1, freq = 2) %&gt;%
  filter(!str_detect(word, &#39;(\\d+)|([A-Za-z]+)|(\\s+)&#39;)) %&gt;% 
  filter(str_length(word) &gt; 1) %&gt;% 
  arrange(-freq) %&gt;% 
  filter(freq &gt; 20)

wordcloud2(dog13_word_overall_freq, size = .6)</code></pre>
<div id="htmlwidget-1" style="width:672px;height:480px;" class="wordcloud2 html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"word":["成长","电影","孩子","青春","世界","李玩","长大","教育","家庭","爱因斯坦","大人","成人","妥协","少女","社会","懂事","保平","中国","爸爸","父亲","中国式","导演","父母","故事","真实","残酷","狗肉","女孩","真的","过程","喜欢","理解","生活","经历","这部","一部","影片","弟弟","家长","青春片","终于","片子","伪善","观众","十三","现实","学会","叛逆","张雪迎","成熟","剧本","青春期","一点","表达","一场","宇宙","配乐","角色","接受","平行","情绪","编剧","共鸣","女主","希望","自我"],"freq":[197,133,115,108,94,91,82,72,70,69,62,61,58,56,54,52,51,51,50,50,49,46,45,45,45,43,43,43,42,40,40,39,39,35,34,32,31,30,30,30,30,29,29,28,28,28,28,27,27,26,26,25,25,24,24,24,23,22,22,22,22,21,21,21,21,21],"fontFamily":"Segoe UI","fontWeight":"bold","color":"random-dark","minSize":0,"weightFactor":0.548223350253807,"backgroundColor":"white","gridSize":0,"minRotation":-0.785398163397448,"maxRotation":0.785398163397448,"shuffle":true,"rotateRatio":0.4,"shape":"circle","ellipticity":0.65,"figBase64":null,"hover":null},"evals":[],"jsHooks":{"render":[{"code":"function(el,x){\n                        console.log(123);\n                        if(!iii){\n                          window.location.reload();\n                          iii = False;\n\n                        }\n  }","data":null}]}}</script>
<p>这部电影的主题应该很明显了。</p>
<p>P.S.再附上另一种不知道该如何进一步使用的模拟登录的方法：</p>
<pre class="r"><code>url &lt;- &#39;https://accounts.douban.com/login?source=movie&#39;
login &lt;- html_session(url)
form &lt;- html_form(login)[[1]]

filled_form &lt;- set_values(form,
                          &#39;form_email&#39; = &#39;用户名&#39;,
                          &#39;form_password&#39; = &#39;密码&#39;)

submit &lt;- submit_form(login, filled_form)</code></pre>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">TAGGED IN</span><br/>
                    
  <a class="tag tag--primary tag--small" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a>

                  </div>
                
              
            
            
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/reading-records-analysis/" data-tooltip="11年-19年读书记录分析">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/12/red-envelope/" data-tooltip="使用R语言模拟抢红包">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/01/pseudo-dynamic-website-scraping/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/01/pseudo-dynamic-website-scraping/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/01/pseudo-dynamic-website-scraping/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 孟祥良. All Rights Reserved
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        
  <div class="post-actions-wrap">
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/02/reading-records-analysis/" data-tooltip="11年-19年读书记录分析">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">NEXT</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2018/12/red-envelope/" data-tooltip="使用R语言模拟抢红包">
              
                  <span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/01/pseudo-dynamic-website-scraping/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/01/pseudo-dynamic-website-scraping/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/01/pseudo-dynamic-website-scraping/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  </div>


      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2019%2F01%2Fpseudo-dynamic-website-scraping%2F">
          <i class="fa fa-facebook-official"></i><span>Share on Facebook</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2019%2F01%2Fpseudo-dynamic-website-scraping%2F">
          <i class="fa fa-twitter"></i><span>Share on Twitter</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2019%2F01%2Fpseudo-dynamic-website-scraping%2F">
          <i class="fa fa-google-plus"></i><span>Share on Google&#43;</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">孟祥良</h4>
    
      <div id="about-card-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</div>
    
    
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/r-resources-collection/">
                <h3 class="media-heading">R语言学习资源总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ArticleConceptHistoryCommunicationBlogdownReportShinyWordMachine LearningBasicsClassificationClusteringDeep LearningDimensionality ReductionPredictionProgramEvaluationFunctionLoopPipeTutorialData AcquisitionOnlinebookTidyverseWebsiteVisualizationAdjustmentBasicCommon PlotsColorExtensionLine ChartMapScatter PlotTheory总结一下我自己看过的R语言学习资源，目前的分类还比较随意，因为很多内容都是交叉的，难以形成明确的体系。没啥特殊情况的话，每个周末都会补充新的内容。另外要强调一点，看教程虽然有助于学习，但真正能提升水平的，还是实践。如果工作中没有太多实践的机会的话，那也要自己想办法找些实践的机会。
还要吐槽一下，不论是tidyverse还是Rmarkdown，对中文的支持都不是很好，用中文标题生成的TOC无法跳转，所以我只好暂时把各部分的标题都写成英文了，以后有时间再琢磨这个问题。不过话说回来，确实是写成英文更方便点，因为我收藏夹里的文件夹名都是英文命名的，而这篇博客其实就是对我的收藏夹内容的总结。
Article收集了一些关于R的概念和历史的文章。
ConceptExplain R environments like I’m five (181110; 190307)
介绍什么是R语言的环境，非常简单易懂。
Environments in R (190128; 190408)</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/04/r-notebook-and-plan/">
                <h3 class="media-heading">R学习笔记及学习计划</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Apr 4, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">人对事物的认识大概可以分为三个层次，从“未知的未知”到“已知的未知”再到“已知的已知”。如果确实是这样的话，那学习就可以分为两种，一种是把“未知的未知”变为“已知的未知”，如了解到这个世界上存在一种叫做“负数”的东西，但不知道它究竟指什么；另一种是把“已知的未知”变为“已知的已知”，如通过进一步的了解，获知“负数”的确切意义。德尔菲的神谕认为没有人比苏格拉底更聪明，其看重的可能并不在于苏格拉底是否比其他所有人拥有更多“已知的已知”，而是看到他比其他人拥有更多“已知的未知”。我不知道两种学习中哪一种更为重要，但我觉得，在大多数情况下，前一种学习都是后一种学习的先决条件。人的时间是有限的，没法把所有的知识都掌握，所以比较好的学习思路可能是先去获取足够多的“已知的未知”，再决定把哪些“已知的未知”转变为“已知的已知”。
我接触R已经三年多了，但真正开始学习R，也就一年多的样子。我对R本身其实没有多大的兴趣，但当我把tidyverse变为“已知的未知”时，才对这门语言产生了热情。翻开哲学的入门书，很有可能会发现最开始的章节是以苏格拉底来划分的，如类似“前苏格拉底时代的哲学家们”的说法。在这里，我也想用tidyverse这个词来对我的笔记章节进行划分（当然，tidyverse对应的哲学家更有可能是笛卡尔），具体来说，包括tidyverse之前，用来介绍R的一些基本知识；tidyverse之内，用来介绍tidyverse核心包的使用方法；tidyverse之上，用来介绍建立在tidyverse核心包基础上的一些实用的包；tidyverse之外，用来介绍与tidyverse无关，但很有用的一些包。当然，这些内容中的很大一部分对我来说还是“已知的未知”。
想弄这么个东西，目的主要有两个：一方面，把自己会的东西以教程的形式写出来，能让自己把“已知的已知”掌握得更牢固；另一方面，也能督促自己不断地去学习新知识，探索“未知的未知”，转化“已知的未知”。因此，内容方面，就包括我目前会的，和我将来想学的，具体内容可以看后面暂定的大纲。另外，我也给自己设定了几个要求：
术语尽量给出参考资料和对应的英文，不知道该如何翻译的直接用英文，符号给出对应的英文及其读音；
尽量保证所有的内容都能跟上R本体和所涉及的包的更新；
暂定的提纲如下：
tidyverse之前R的介绍及安装
R的基本概念及操作
R中的条件与循环
tidyveRse之内使用readr导入数据
使用rvest获取网络数据
dbplyr与数据库
dplyr包常用操作及管道操作符
tidyr包常用操作及tidy data
stringr包常用操作及正则表达式
forcats常用操作
lubridate常用操作
purrr包探索
组合使用
tidyverse代码风格
ggplot2基本统计图的绘制
ggplot2统计图的调整
ggplot2统计图的美化
tidyverse之上使用tidytext进行文本分析
使用ggvis绘制交互统计图
使用gganimate绘制动态统计图
tidyverse之外使用rmarkdown撰写报告
使用blogdown搭建博客
使用shiny制作网络应用</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/03/r-basic-concept-and-operation/">
                <h3 class="media-heading">R的基本概念和操作</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">R的基本操作a.计算b.逻辑运算c.赋值R的基本概念a.数据结构数据探索b.函数c.包190323
R的基本操作a.计算R可以作为计算器使用，+、-、*、/、^分别代表加减乘除和乘方：
2 ^ 2 / 2 - (2 * 2 + 2)## [1] -4%%求余数，%/%求商：
5 %% 2## [1] 15 %/% 2## [1] 2b.逻辑运算==、!=、&gt;、&gt;=、&lt;、&lt;=分别用来判断相等、不等、大于、大于等于、小于、小于等于的关系，符合逻辑返回TRUE，反之返回FALSE。对于部分字符（英文字母和汉字），似乎是字母顺序排在后面的更大；对于字符型数值，似乎与其数值型数值相等；另外，逻辑型数值中，TRUE等于1，而FALSE等于0：
TRUE == 1## [1] TRUEFALSE == 0## [1] TRUE&#39;白马&#39; != &#39;马&#39;## [1] TRUE1 == &#39;1&#39;## [1] TRUE&#39;x&#39; &lt; &#39;y&#39;## [1] TRUE&#39;一&#39; &gt; &#39;二&#39;## [1] TRUEc.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/03/r-introduction-and-installation/">
                <h3 class="media-heading">R的介绍和安装</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">R的介绍R的简介R的优势R的学习方法R的安装RStudio的安装RStudio简介RStudio的布局RStudio的设置190320
R的介绍R的简介R是一种编程语言，是可以用来进行统计计算和绘图的免费软件。
R的优势有一些文章介绍了R的优势，如：Why I use R for Data Science - An Ode to R；6 REASONS TO LEARN R FOR BUSINESS。不过对我来说，主要的优势还是以下几个：
免费；
无需太多的编程知识（在tidyverse等包的帮助下，即便没有正式的计算机科学或软件工程训练也能比较容易地上手）；
RStudio这个IDE（Integrated Development Environment，集成开发环境）太好用了；
R的学习方法直接学习tidyverse，参考：
Don’t teach built-in plotting to beginners (teach ggplot2)：
Teach the tidyverse to beginners；
Don’t teach students the hard way first；研究生阶段，同学曾给我一份代码，包括以下部分：</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/02/reading-records-analysis/">
                <h3 class="media-heading">11年-19年读书记录分析</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/01/pseudo-dynamic-website-scraping/">
                <h3 class="media-heading">（伪）动态网页爬虫-《狗十三》豆瓣短评爬取</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jan 1, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/12/red-envelope/">
                <h3 class="media-heading">使用R语言模拟抢红包</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">有一次参加了一个特别无聊的讲座，实在是无事可做，就琢磨了一下像微信抢红包那样的机制是如何实现的。自己当时想了一个模拟的方式，出来的结果似乎也可以以假乱真。后来把相关的代码完善了下，用来在自己组织的R语言课上讲for循环和自编函数。现在把这些内容整理出来，权当作一篇小小的教程。
首先假设，有人发了一个200块钱的红包，分给10个人抢：
money &lt;- 200people &lt;- 10给每个人安排一个随机数：
set.seed(181209)rand_number &lt;- sample(1:10000, people, replace = TRUE)rand_number## [1] 4188 591 2386 4520 3692 979 8170 3728 7121 4408随后用每个随机数除以所有随机数的总和得到一个比值，乘以总钱数，进而得到每个人的钱数：
rand_money &lt;- rand_number/sum(rand_number)*moneyrand_money## [1] 21.054219 2.971118 11.995073 22.723274 18.560692 4.921700 41.072820## [8] 18.741674 35.799211 22.160219然后就可以知道具体每个人得到多少钱了：
paste0(paste0(sample(letters, 5, replace = TRUE), collapse = &#39;&#39;),&#39;得到了&#39;, round(rand_money[1], 2), &#39;元，红包剩余&#39;, round(money - sum(rand_money[1:1]), 2), &#39;元。&#39;)## [1] &quot;hdprm得到了21.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/ggplot2-collection/">
                <h3 class="media-heading">ggplot2及其扩展包绘图总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Bar PlotBox PlotHeatmapHistgramLine ChartMapPie ChartRadar ChartScatter PlotTreemap像这样的教程应该有很多了，但为了自己查阅起来方便，我决定自己也写一个。这里我会尽量多的用到各种theme和palette，省得每次绘图还要一个一个试，看哪个好看（通过这个过程，我可能体验到了女生出门前挑衣服的感觉）。
先把需要用到的包载入：
library(tidyverse)library(ggthemes)Bar Plot直条图应该是最常见的了，在心理学论文中用到直条图时，一般都是把自变量放到x轴上，因变量放到y轴上，然后再添加误差条：
iris %&gt;% group_by(Species) %&gt;% summarise(avg_sl = mean(Sepal.Length), se = sqrt(sd(Sepal.Length)/n())) %&gt;% ggplot(aes(Species, avg_sl, fill = Species)) + geom_col(width = .5) + geom_errorbar(aes(ymin = avg_sl - se, ymax = avg_sl + se),width = .3) + scale_y_continuous(expand = c(0, 0)) + scale_fill_brewer(palette = &#39;Set2&#39;) + labs(y = &#39;Sepal.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/text-analysis-for-tianlong/">
                <h3 class="media-heading">利用文本分析对比两版本天龙八部</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">今年三月份，为了掌握文本分析技术，特意找了两个版本《天龙八部》的txt文件作为数据而进行练习，但可能被其他事情给耽搁了，当时只完成了一部分。前几天金老去世，令人不胜感概，于是想把这个《天龙八部》的文本分析完成，也算是以自己的方式表达对大师的怀念。
首先还是载入相关的包，这次的包有点多：
library(tidyverse)library(readxl)library(tidytext)library(jiebaR)library(ggthemes)library(widyr)library(igraph)library(ggraph)然后将两个版本的小说文本导入，顺便导入了主要人物的人名，因为这次分析是以分析主要人物为主：
tl_new &lt;- read_lines(&#39;tl_new.txt&#39;)tl_old &lt;- read_lines(&#39;tl_old.txt&#39;)tl_main &lt;- read_lines(&#39;tl_main.txt&#39;) %&gt;% .[-1]因为每个人的称呼不止一个，如乔帮主、萧大王、姊夫等等，都是指萧峰一个人，所以为了统一人名，还要做一些替换工作：
tl_new_tran &lt;- tl_new %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)tl_old_tran &lt;- tl_old %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)上面的替换工作并不全，比如，同样是段郞，有时可能是指段誉，有时可能是指段正淳，这就需要具体的情境，才能判断出来这个词指的是谁，但这个工作太麻烦了，这里就放弃了。</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/rick-and-morty-heatmap/">
                <h3 class="media-heading">看图写代码：瑞克与莫蒂剧集评分热力图</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">大概是去年的这个时间，我在一个名叫Data Is Beautiful的reddit论坛上看到了一张Rick and Morty的分集评分热力图，就想用R把它重复出来。当时水平还不怎么样，只能画个大概出来，很多细节都不知道该如何呈现；前几个月，又重新尝试了下，大部分细节都知道该如何实现了，但还是差一点；这里再尝试一下，看看能不能完全重复出来，毕竟这张图应该就是用R画的。
图是这样的：
首先，还是先把需要用到的包载入：
library(tidyverse)然后载入数据：
rm &lt;- read_csv(&quot;rick &amp; morty.csv&quot;) %&gt;% mutate_at(vars(Episode, Season), as.factor)载入数据的时候，为方便后面的绘图，顺便把集数和季数两个变量改成了因子型。具体的数据是这样的：
rm## # A tibble: 31 x 3## Episode Season Rating## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;## 1 1 1 8.1## 2 2 1 8.7## 3 3 1 8.4## 4 4 1 8.6## 5 5 1 8.9## 6 6 1 9 ## 7 7 1 8.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         13 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/cover.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2019\/01\/pseudo-dynamic-website-scraping\/';
          
            this.page.identifier = '\/2019\/01\/pseudo-dynamic-website-scraping\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'hugo-tranquilpeak-theme';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  



    
  </body>
</html>

