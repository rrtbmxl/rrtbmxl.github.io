


  




  


  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.31.1 with theme Tranquilpeak 0.4.3-BETA">
    <title>RPG</title>
    <meta name="author" content="孟祥良">
    <meta name="keywords" content="">

    <link rel="icon" href="/favicon.png">
    
      <link rel="alternate" type="application/rss+xml" title="RSS" href="/index.xml">
    

    
    <meta name="description" content="Hugo tranquilpeak theme demo">
    <meta property="og:description" content="Hugo tranquilpeak theme demo">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="RPG">
    <meta property="og:url" content="/">
    <meta property="og:site_name" content="RPG">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="RPG">
    <meta name="twitter:description" content="Hugo tranquilpeak theme demo">
    
    

    
    

    
      <meta property="og:image" content="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=640">
    

    
    
    

    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">RPG</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=90" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">孟祥良</h4>
        
          <h5 class="sidebar-profile-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/rrtbmxl/rrtbmxl.github.io">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      
      
      <span class="sidebar-button-desc"></span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <section class="postShorten-group main-content-wrap">
          
          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2019/02/reading-records-analysis/">
          11年-19年读书记录分析
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-02-16T00:00:00Z">
        
  February 16, 2019

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.
      <p>
        <a href="/2019/02/reading-records-analysis/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2019/01/r-source-collection/">
          R语言学习资源总结
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-01-28T00:00:00Z">
        
  January 28, 2019

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      ArticleAdvantageConceptHistoryLearningCommunicationBlogdownReportShinyWordTutorialWebsiteData AcquisitionMachine LearningOnlinebookProgramTidyverseVisualizationAdjustmentBasicColorExtensionHistogramLine ChartMapScatter PlotTheory总结一下我自己看过的R语言学习资源，目前的分类还比较随意，因为很多内容都是交叉的，难以形成明确的体系。没啥特殊情况的话，每个周末都会补充新的内容。另外要强调一点，看教程虽然有助于学习，但真正能提升水平的，还是实践。如果工作中没有太多实践的机会的话，那也要自己想办法找些实践的机会。
还要吐槽一下，不论是tidyverse还是Rmarkdown，对中文的支持都不是很好，用中文标题生成的TOC无法跳转，所以我只好暂时把各部分的标题都写成英文了，以后有时间再琢磨这个问题。不过话说回来，确实是写成英文更方便点，因为我收藏夹里的文件夹名都是英文命名的，而这篇博客其实就是对我的收藏夹内容的总结。
Article这里罗列了一些关于R语言的文章，主要包括R的优势、R的一些概念、R的历史以及如何学习R。
AdvantageWhy I use R for Data Science - An Ode to R（181110）介绍了R语言的一些优点，作者是从R开始接触编程语言的，观点可能有失偏颇；我也差不多是从R开始接触编程语言的，所以是不是真的偏颇了，我也看不出来。
6 REASONS TO LEARN R FOR BUSINESS（181110）从商业领域的角度谈为什么要学习R，这个是有数据支持的，比较令人信服。
ConceptWindow functions（181110）介绍了什么是window function，感觉我目前还没有把这个概念完全吃透，但后面有一些dplyr包的使用技巧，值得一看。
      <p>
        <a href="/2019/01/r-source-collection/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2019/01/pseudo-dynamic-website-scraping/">
          （伪）动态网页爬虫-《狗十三》豆瓣短评爬取
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-01-06T00:00:00Z">
        
  January 6, 2019

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.
      <p>
        <a href="/2019/01/pseudo-dynamic-website-scraping/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2018/12/red-envelope/">
          使用R语言模拟抢红包
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-12-09T00:00:00Z">
        
  December 9, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      有一次参加了一个特别无聊的讲座，实在是无事可做，就琢磨了一下像微信抢红包那样的机制是如何实现的。自己当时想了一个模拟的方式，出来的结果似乎也可以以假乱真。后来把相关的代码完善了下，用来在自己组织的R语言课上讲for循环和自编函数。现在把这些内容整理出来，权当作一篇小小的教程。
首先假设，有人发了一个200块钱的红包，分给10个人抢：
money &lt;- 200people &lt;- 10给每个人安排一个随机数：
set.seed(181209)rand_number &lt;- sample(1:10000, people, replace = TRUE)rand_number## [1] 4188 591 2386 4520 3692 979 8170 3728 7121 4408随后用每个随机数除以所有随机数的总和得到一个比值，乘以总钱数，进而得到每个人的钱数：
rand_money &lt;- rand_number/sum(rand_number)*moneyrand_money## [1] 21.054219 2.971118 11.995073 22.723274 18.560692 4.921700 41.072820## [8] 18.741674 35.799211 22.160219然后就可以知道具体每个人得到多少钱了：
paste0(paste0(sample(letters, 5, replace = TRUE), collapse = &#39;&#39;),&#39;得到了&#39;, round(rand_money[1], 2), &#39;元，红包剩余&#39;, round(money - sum(rand_money[1:1]), 2), &#39;元。&#39;)## [1] &quot;hdprm得到了21.05元，红包剩余178.95元。&quot;paste0(paste0(sample(letters, 5, replace = TRUE), collapse = &#39;&#39;),&#39;得到了&#39;, round(rand_money[2], 2), &#39;元，红包剩余&#39;, round(money - sum(rand_money[1:2]), 2), &#39;元。&#39;)## [1] &quot;ptdpj得到了2.
      <p>
        <a href="/2018/12/red-envelope/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2018/11/ggplot2-collection/">
          ggplot2及其扩展包绘图总结
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-11-18T00:00:00Z">
        
  November 18, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      Bar PlotBox PlotHeatmapHistgramLine ChartMapPie ChartRadar ChartScatter PlotTreemap像这样的教程应该有很多了，但为了自己查阅起来方便，我决定自己也写一个。这里我会尽量多的用到各种theme和palette，省得每次绘图还要一个一个试，看哪个好看（通过这个过程，我可能体验到了女生出门前挑衣服的感觉）。
先把需要用到的包载入：
library(tidyverse)library(ggthemes)Bar Plot直条图应该是最常见的了，在心理学论文中用到直条图时，一般都是把自变量放到x轴上，因变量放到y轴上，然后再添加误差条：
iris %&gt;% group_by(Species) %&gt;% summarise(avg_sl = mean(Sepal.Length), se = sqrt(sd(Sepal.Length)/n())) %&gt;% ggplot(aes(Species, avg_sl, fill = Species)) + geom_col(width = .5) + geom_errorbar(aes(ymin = avg_sl - se, ymax = avg_sl + se),width = .3) + scale_y_continuous(expand = c(0, 0)) + scale_fill_brewer(palette = &#39;Set2&#39;) + labs(y = &#39;Sepal.
      <p>
        <a href="/2018/11/ggplot2-collection/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2018/11/text-analysis-for-tianlong/">
          利用文本分析对比两版本天龙八部
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-11-04T00:00:00Z">
        
  November 4, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      今年三月份，为了掌握文本分析技术，特意找了两个版本《天龙八部》的txt文件作为数据而进行练习，但可能被其他事情给耽搁了，当时只完成了一部分。前几天金老去世，令人不胜感概，于是想把这个《天龙八部》的文本分析完成，也算是以自己的方式表达对大师的怀念。
首先还是载入相关的包，这次的包有点多：
library(tidyverse)library(readxl)library(tidytext)library(jiebaR)library(ggthemes)library(widyr)library(igraph)library(ggraph)然后将两个版本的小说文本导入，顺便导入了主要人物的人名，因为这次分析是以分析主要人物为主：
tl_new &lt;- read_lines(&#39;tl_new.txt&#39;)tl_old &lt;- read_lines(&#39;tl_old.txt&#39;)tl_main &lt;- read_lines(&#39;tl_main.txt&#39;) %&gt;% .[-1]因为每个人的称呼不止一个，如乔帮主、萧大王、姊夫等等，都是指萧峰一个人，所以为了统一人名，还要做一些替换工作：
tl_new_tran &lt;- tl_new %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)tl_old_tran &lt;- tl_old %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)上面的替换工作并不全，比如，同样是段郞，有时可能是指段誉，有时可能是指段正淳，这就需要具体的情境，才能判断出来这个词指的是谁，但这个工作太麻烦了，这里就放弃了。
      <p>
        <a href="/2018/11/text-analysis-for-tianlong/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
</article>

          
            
  
    
      
        
      
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2018/10/rick-and-morty-heatmap/">
          看图写代码：瑞克与莫蒂剧集评分热力图
        </a>
      </h1>
      
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2018-10-28T00:00:00Z">
        
  October 28, 2018

      </time>
    
    
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/r">R</a>
    
  

  </div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      大概是去年的这个时间，我在一个名叫Data Is Beautiful的reddit论坛上看到了一张Rick and Morty的分集评分热力图，就想用R把它重复出来。当时水平还不怎么样，只能画个大概出来，很多细节都不知道该如何呈现；前几个月，又重新尝试了下，大部分细节都知道该如何实现了，但还是差一点；这里再尝试一下，看看能不能完全重复出来，毕竟这张图应该就是用R画的。
图是这样的：
首先，还是先把需要用到的包载入：
library(tidyverse)然后载入数据：
rm &lt;- read_csv(&quot;rick &amp; morty.csv&quot;) %&gt;% mutate_at(vars(Episode, Season), as.factor)载入数据的时候，为方便后面的绘图，顺便把集数和季数两个变量改成了因子型。具体的数据是这样的：
rm## # A tibble: 31 x 3## Episode Season Rating## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;## 1 1 1 8.1## 2 2 1 8.7## 3 3 1 8.4## 4 4 1 8.6## 5 5 1 8.9## 6 6 1 9 ## 7 7 1 8.
      <p>
        <a href="/2018/10/rick-and-morty-heatmap/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
</article>

          
          
  <div class="pagination-bar">
    <ul class="pagination">
      
        
        
          <li class="pagination-next">
            <a class="btn btn--default btn--small" href="/page/2/">
              <span>OLDER POSTS</span>
              <i class="fa fa-angle-right text-base icon-ml"></i>
            </a>
          </li>
        
      
      <li class="pagination-number">page 1 of 2</li>
    </ul>
  </div>


        </section>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 孟祥良. All Rights Reserved
  </span>
</footer>

      </div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="//www.gravatar.com/avatar/9a7089fad6e7d2ebee69f9659db0c484?s=110" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">孟祥良</h4>
    
      <div id="about-card-bio">R语言爱好者, 心理学专业硕士 &amp; FGO休闲玩家</div>
    
    
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/02/reading-records-analysis/">
                <h3 class="media-heading">11年-19年读书记录分析</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">大概在10年前后，镇上给村里弄了个农村书屋，其他办公室都没地方，就把书连书柜都放我办公室里了。当时统计了下，一共有1500多本书，后来又给了一批，最终达到1800多本。这些书中的大部分质量和内容都很一般，但还是有几本好书的。反正工作也挺闲的，每天就靠看书打发点时间。时过境迁，工作已经换了几个，但看书的习惯还一直保持着。
我从12年开始记日记，所以从那一年起，哪段时间看了哪本书都有记录。前几年把读书的记录整理过一次，但信息不全；今年过年前后，花了几天的时间又整理了一遍，添加了一些书籍相关的信息，就想着要不要也分析下（其实只是统计，并没有分析），算是对这些年自己读书的一个总结。有点遗憾的是，11年的记录只找到10月份到12月份的一部分，10月份以前的则完全没有记录，就没法统计进来了。
但在分析之前，还得说明一下，有些书我没有进行统计，这些书包括以下四种：
国产教材。比如为考研而看的《普通心理学》《心理学导论》之类的，但国外的教材，如《心理学与生活》等，不在此列。
技术类的书。如跟R相关的书，有实体的，也有在线的，都没有被统计进来。
电子书。不论是在手机上，kindle上，还是在更早的汉王上看的电子书，都没有统计进来。在看书这方面，我还是比较传统的，现在基本上只看实体书。
太low的书。如，有套书名叫《卑鄙的圣人：曹操》，老爹看见了，非要买一套，当时只出了5本，就都买了下来。我是家里有的书就要看完的（大概就是看完这套书后改了这个“毛病”），就硬着头皮把这几本书看了一遍。听说这套书让作者赚了一百多万的版税，但这也无法掩盖作者文笔一般、词汇匮乏的事实。印象最深的是，曹操笑起来是“噗嗤”，袁绍笑起来也“噗嗤”，连曹操的老子曹嵩笑起来也“噗嗤”，这到底是一群大老爷们，还是一群小丫头片子啊（当然，用在曹嵩身上也许是合适的）？总之，这类书就不进行统计了。
去掉以上四类书之后，剩下的书（共计465本次），就是要进行分析的了。
首先还是载入分析需要用到的包：
library(tidyverse)library(readxl)library(knitr)然后把数据导入并进行清洗。由于数据已经在excel里整理好了，所以也没啥好清洗的，只是对每本书的字数进行了校正：
book &lt;- read_xlsx(&#39;读书记录.xlsx&#39;) %&gt;% select(year = 2, name = 4, publisher = 6, author = 7, country = 8, dynasty = 9, classification = 10, language = 11, price = 12, page = 13, words = 14, manner = 15) %&gt;% mutate(words = case_when(language %in% c(&#39;古汉&#39;, &#39;英汉&#39;) ~ words*1.3,language %in% c(&#39;古语&#39;, &#39;英语&#39;) ~ words*2,TRUE ~ words),words = ifelse(manner == &#39;书内&#39;, words*.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/01/r-source-collection/">
                <h3 class="media-heading">R语言学习资源总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jan 1, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ArticleAdvantageConceptHistoryLearningCommunicationBlogdownReportShinyWordTutorialWebsiteData AcquisitionMachine LearningOnlinebookProgramTidyverseVisualizationAdjustmentBasicColorExtensionHistogramLine ChartMapScatter PlotTheory总结一下我自己看过的R语言学习资源，目前的分类还比较随意，因为很多内容都是交叉的，难以形成明确的体系。没啥特殊情况的话，每个周末都会补充新的内容。另外要强调一点，看教程虽然有助于学习，但真正能提升水平的，还是实践。如果工作中没有太多实践的机会的话，那也要自己想办法找些实践的机会。
还要吐槽一下，不论是tidyverse还是Rmarkdown，对中文的支持都不是很好，用中文标题生成的TOC无法跳转，所以我只好暂时把各部分的标题都写成英文了，以后有时间再琢磨这个问题。不过话说回来，确实是写成英文更方便点，因为我收藏夹里的文件夹名都是英文命名的，而这篇博客其实就是对我的收藏夹内容的总结。
Article这里罗列了一些关于R语言的文章，主要包括R的优势、R的一些概念、R的历史以及如何学习R。
AdvantageWhy I use R for Data Science - An Ode to R（181110）介绍了R语言的一些优点，作者是从R开始接触编程语言的，观点可能有失偏颇；我也差不多是从R开始接触编程语言的，所以是不是真的偏颇了，我也看不出来。
6 REASONS TO LEARN R FOR BUSINESS（181110）从商业领域的角度谈为什么要学习R，这个是有数据支持的，比较令人信服。
ConceptWindow functions（181110）介绍了什么是window function，感觉我目前还没有把这个概念完全吃透，但后面有一些dplyr包的使用技巧，值得一看。</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/01/pseudo-dynamic-website-scraping/">
                <h3 class="media-heading">（伪）动态网页爬虫-《狗十三》豆瓣短评爬取</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jan 1, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">这周公司组织了电影赏析，看的电影是《狗十三》。我之前并没有看过这部电影，就想着先去豆瓣上看一下评论。这电影的评论还不少，有好几百条，完全可以全爬下来，分析一下。拉到页面下面，点击后页，url就会跟着变化（start=那里），说明这也不是啥动态网页，完全可以写个循环，用rvest包一页一页的爬。但实际爬取的时候，遇到了问题，就是未登陆的状态下，只能爬前220条评论。我搜索了一下模拟登录的办法，似乎是成功了，但后续该怎么弄，我就不知道了。我在这里卡了一天，没想到解决办法。昨天早上躺在被窝里，突然想到，我之前研究了下用RSelenium爬取动态网页，这里我完全可以先用RSelenium模拟登录，然后把网页当成动态网页爬啊。试了一下，成功了，下面就是相关的操作过程。
首先还是载入需要用的包，要使用RSelenium包，还要先进行一些配置，具体内容可以看RSelenium包的官方网站（这网站好像需要科学上网）：
library(tidyverse)library(RSelenium)library(rvest)library(jiebaR)library(wordcloud2)library(knitr)接下来跟Selenium Server进行连接，这里我用的是Chrome浏览器（变量名rd本应该在第一行，不知道为什么跑到下边去了……）：
 rd &lt;- remoteDriver(remoteServerAddr = &quot;localhost&quot;,port = 4444L,browserName = &quot;chrome&quot;)然后模拟打开豆瓣电影的登录页面，输入用户名和密码，点击登录按键，就可以登录了：
rd$open()rd$navigate(&#39;https://www.douban.com/accounts/login?source=movie&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;email&quot;]&#39;)we$sendKeysToElement(list(&#39;用户名&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;password&quot;]&#39;)we$sendKeysToElement(list(&#39;密码&#39;))we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;lzform&quot;]/div[6]/input&#39;)we$clickElement()如果没接触过爬虫的，看着上面的代码可能有点懵，但实际上没啥太玄奥的东西。RSelenium包中的函数名就明白显示了它是干什么的，而参数中的那些xpath，在Chrome浏览器中都是可以直接复制出来的。
后面就可以开始爬虫了。我只爬了评价星级、短评时间、有帮助次数和短评文本四项信息。需要说明的是，有些用户虽然写了短评，但不会打分，这种情况下，我认为的将其评价星级定位“无评价”。因为不打分也会影响后面内容的xpath，所以那部分用了一些if条件。另外，虽然不知道会不会用上，在每页的内容爬取完之后，我也会让程序随机休息几秒，省得被轻易地认定为是爬虫程序。
rd$navigate(&#39;https://movie.douban.com/subject/25716096/comments?start=0&amp;limit=20&amp;sort=new_score&amp;status=P&#39;)dog13 &lt;- tibble()for (i in 1:50) {rank &lt;- character(0)time &lt;- character(0)help &lt;- character(0)text &lt;- character(0)temp &lt;- tibble()for (j in 1:20) {xpath_rank &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_rank)rank[j] &lt;- ifelse(str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &gt; 2, &#39;无评价&#39;, we$getElementAttribute(&#39;title&#39;) %&gt;% unlist())if (str_length(we$getElementAttribute(&#39;title&#39;) %&gt;% unlist()) &lt; 3) {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[3]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()} else {xpath_time &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[2]/span[2]&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_time)time[j] &lt;- we$getElementText() %&gt;% unlist()}xpath_help &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/h3/span[1]/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_help)help[j] &lt;- we$getElementText() %&gt;% unlist()xpath_text &lt;- str_c(&#39;//*[@id=&quot;comments&quot;]/div[&#39;, j, &#39;]/div[2]/p/span&#39;)we &lt;- rd$findElement(using = &#39;xpath&#39;, xpath_text)text[j] &lt;- we$getElementText() %&gt;% unlist()df &lt;- tibble(rank, time, help, text)}dog13 &lt;- bind_rows(dog13, df)rest &lt;- sample(1:10, 1)if (i &lt; 2) {we &lt;- rd$findElement(using = &#39;xpath&#39;, &#39;//*[@id=&quot;paginator&quot;]/a&#39;)we$clickElement()Sys.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/12/red-envelope/">
                <h3 class="media-heading">使用R语言模拟抢红包</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Dec 12, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">有一次参加了一个特别无聊的讲座，实在是无事可做，就琢磨了一下像微信抢红包那样的机制是如何实现的。自己当时想了一个模拟的方式，出来的结果似乎也可以以假乱真。后来把相关的代码完善了下，用来在自己组织的R语言课上讲for循环和自编函数。现在把这些内容整理出来，权当作一篇小小的教程。
首先假设，有人发了一个200块钱的红包，分给10个人抢：
money &lt;- 200people &lt;- 10给每个人安排一个随机数：
set.seed(181209)rand_number &lt;- sample(1:10000, people, replace = TRUE)rand_number## [1] 4188 591 2386 4520 3692 979 8170 3728 7121 4408随后用每个随机数除以所有随机数的总和得到一个比值，乘以总钱数，进而得到每个人的钱数：
rand_money &lt;- rand_number/sum(rand_number)*moneyrand_money## [1] 21.054219 2.971118 11.995073 22.723274 18.560692 4.921700 41.072820## [8] 18.741674 35.799211 22.160219然后就可以知道具体每个人得到多少钱了：
paste0(paste0(sample(letters, 5, replace = TRUE), collapse = &#39;&#39;),&#39;得到了&#39;, round(rand_money[1], 2), &#39;元，红包剩余&#39;, round(money - sum(rand_money[1:1]), 2), &#39;元。&#39;)## [1] &quot;hdprm得到了21.05元，红包剩余178.95元。&quot;paste0(paste0(sample(letters, 5, replace = TRUE), collapse = &#39;&#39;),&#39;得到了&#39;, round(rand_money[2], 2), &#39;元，红包剩余&#39;, round(money - sum(rand_money[1:2]), 2), &#39;元。&#39;)## [1] &quot;ptdpj得到了2.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/ggplot2-collection/">
                <h3 class="media-heading">ggplot2及其扩展包绘图总结</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">Bar PlotBox PlotHeatmapHistgramLine ChartMapPie ChartRadar ChartScatter PlotTreemap像这样的教程应该有很多了，但为了自己查阅起来方便，我决定自己也写一个。这里我会尽量多的用到各种theme和palette，省得每次绘图还要一个一个试，看哪个好看（通过这个过程，我可能体验到了女生出门前挑衣服的感觉）。
先把需要用到的包载入：
library(tidyverse)library(ggthemes)Bar Plot直条图应该是最常见的了，在心理学论文中用到直条图时，一般都是把自变量放到x轴上，因变量放到y轴上，然后再添加误差条：
iris %&gt;% group_by(Species) %&gt;% summarise(avg_sl = mean(Sepal.Length), se = sqrt(sd(Sepal.Length)/n())) %&gt;% ggplot(aes(Species, avg_sl, fill = Species)) + geom_col(width = .5) + geom_errorbar(aes(ymin = avg_sl - se, ymax = avg_sl + se),width = .3) + scale_y_continuous(expand = c(0, 0)) + scale_fill_brewer(palette = &#39;Set2&#39;) + labs(y = &#39;Sepal.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/11/text-analysis-for-tianlong/">
                <h3 class="media-heading">利用文本分析对比两版本天龙八部</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Nov 11, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">今年三月份，为了掌握文本分析技术，特意找了两个版本《天龙八部》的txt文件作为数据而进行练习，但可能被其他事情给耽搁了，当时只完成了一部分。前几天金老去世，令人不胜感概，于是想把这个《天龙八部》的文本分析完成，也算是以自己的方式表达对大师的怀念。
首先还是载入相关的包，这次的包有点多：
library(tidyverse)library(readxl)library(tidytext)library(jiebaR)library(ggthemes)library(widyr)library(igraph)library(ggraph)然后将两个版本的小说文本导入，顺便导入了主要人物的人名，因为这次分析是以分析主要人物为主：
tl_new &lt;- read_lines(&#39;tl_new.txt&#39;)tl_old &lt;- read_lines(&#39;tl_old.txt&#39;)tl_main &lt;- read_lines(&#39;tl_main.txt&#39;) %&gt;% .[-1]因为每个人的称呼不止一个，如乔帮主、萧大王、姊夫等等，都是指萧峰一个人，所以为了统一人名，还要做一些替换工作：
tl_new_tran &lt;- tl_new %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)tl_old_tran &lt;- tl_old %&gt;% str_replace_all(&#39;(段公子)|(哥哥)|(誉儿)&#39;, &#39;段誉&#39;) %&gt;%str_replace_all(&#39;(乔峰)|(乔帮主)|(姊夫)|(萧大王)&#39;, &#39;萧峰&#39;) %&gt;% str_replace_all(&#39;(梦郎)|(小和尚)&#39;, &#39;虚竹&#39;) %&gt;% str_replace_all(&#39;(南海鳄神)|(岳老二)&#39;, &#39;岳老三&#39;) %&gt;% str_replace_all(&#39;带头大哥&#39;, &#39;玄慈&#39;) %&gt;% str_replace_all(&#39;延庆太子&#39;, &#39;段延庆&#39;) %&gt;% str_replace_all(&#39;白长老&#39;, &#39;白世镜&#39;) %&gt;% str_replace_all(&#39;全舵主&#39;, &#39;全冠清&#39;) %&gt;% str_replace_all(&#39;甘宝宝&#39;, &#39;钟夫人&#39;) %&gt;% str_replace_all(&#39;小康&#39;, &#39;马夫人&#39;) %&gt;% str_replace_all(&#39;灵儿&#39;, &#39;钟灵&#39;) %&gt;% str_replace_all(&#39;(星宿老怪)|(星宿老仙)&#39;, &#39;丁春秋&#39;) %&gt;% str_replace_all(&#39;庄聚贤&#39;, &#39;游坦之&#39;) %&gt;% str_replace_all(&#39;(慕容公子)|(表哥)&#39;, &#39;慕容复&#39;) %&gt;% str_replace_all(&#39;国师&#39;, &#39;鸠摩智&#39;) %&gt;% str_replace_all(&#39;表妹&#39;, &#39;王语嫣&#39;) %&gt;% str_replace_all(&#39;(婉妹)|(木姊姊)&#39;, &#39;木婉清&#39;) %&gt;% str_replace_all(&#39;(郡主)|(小师妹)&#39;, &#39;阿紫&#39;) %&gt;% str_replace_all(&#39;段王爷&#39;, &#39;段正淳&#39;)上面的替换工作并不全，比如，同样是段郞，有时可能是指段誉，有时可能是指段正淳，这就需要具体的情境，才能判断出来这个词指的是谁，但这个工作太麻烦了，这里就放弃了。</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/rick-and-morty-heatmap/">
                <h3 class="media-heading">看图写代码：瑞克与莫蒂剧集评分热力图</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">大概是去年的这个时间，我在一个名叫Data Is Beautiful的reddit论坛上看到了一张Rick and Morty的分集评分热力图，就想用R把它重复出来。当时水平还不怎么样，只能画个大概出来，很多细节都不知道该如何呈现；前几个月，又重新尝试了下，大部分细节都知道该如何实现了，但还是差一点；这里再尝试一下，看看能不能完全重复出来，毕竟这张图应该就是用R画的。
图是这样的：
首先，还是先把需要用到的包载入：
library(tidyverse)然后载入数据：
rm &lt;- read_csv(&quot;rick &amp; morty.csv&quot;) %&gt;% mutate_at(vars(Episode, Season), as.factor)载入数据的时候，为方便后面的绘图，顺便把集数和季数两个变量改成了因子型。具体的数据是这样的：
rm## # A tibble: 31 x 3## Episode Season Rating## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;## 1 1 1 8.1## 2 2 1 8.7## 3 3 1 8.4## 4 4 1 8.6## 5 5 1 8.9## 6 6 1 9 ## 7 7 1 8.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/10/%E6%97%A5%E8%AE%B0%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/">
                <h3 class="media-heading">日记文本分析：第一部分</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Oct 10, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">据说希腊的德尔菲神庙上刻着几条箴言，其中一条告诫我们要“认识你自己”。这条箴言刻起来容易，做起来却很难，甚至可能是人生最困难的事情之一。要想认识自己，大概有四种方法，一是客观内容的客观描述，如测量人的身高、体重等各种身体特征，这些特征在一定的时间内不会有太大幅度的变化，用来测量这些特征的工具也具有极高的信度和效度，因此不论从要了解的内容和用于了解该内容的方式，都是很客观的；二是客观内容的主观描述，如使用问卷量表测量人的各种能力，人的能力应该也是比较恒定的，但用于测量这些特征的工具，无论是编制过程还是施用过程，都避免不了与人为因素有关的干扰，即便硬要说它是客观的，也是“主观”的客观。三是主观内容的主观描述，如各种投射测验，对于这些测验，我没有实际接触过，但从书本上来看，难免不让我认为这种测验从内容到方式都不是那么客观；最后一种就显而易见了，即对主观内容的客观描述，如对推特的文本分析，我要进行的日记文本分析，也是这一范围之内的。日记本身是主观的产物，但这里我要对这些主观的内容进行客观的数据分析，进而从这一角度来加深对自己的了解，不过这个方法的局限性也很大，毕竟不是每个人都有几十万字的日记文本可以用来分析。另外再加一句，上面这段话，也可以说是对客观内容的主观描述。
这篇文章分为三部分，首先是对我每天记日记的时间进行一个简单的分析，然后对文本进行分词，针对词频进行分析，最后是一个初步的情感分析。下面先载入需要用到的包。
导入需要的包library(tidyverse)library(readxl)library(jiebaR)library(ggthemes)一般情况下，我的第一行代码都是library(tidyverse)，这次主要用到了其中dplyr、tidyr、stringr以及ggplot2四个包；readxl包用来读入.xlsx格式的文件；jiebarR用来分词；ggthemes用来添加我最喜欢的tufte主题。
时间分析首先要把日记中与时间有关的内容提取出来，我记录时间的格式很固定，都是20XX年X月X日 周X XX：XX的形式，通过以下代码，可以把这部分内容提取出来：
time &lt;- read_lines(&#39;dairy.txt&#39;) %&gt;% as.tibble() %&gt;% filter(str_detect(value, &#39;.*年.*月.*日.*周&#39;)) %&gt;% mutate(num = row_number()) %&gt;% select(2, time = 1)处理后是这个样子的：
numtime12012年1月13日 周五 21：4022012年1月14日 周六 21：4132012年1月15日 周日 21：5342012年1月16日 周一 21：5852012年1月17日 周二 21：4562012年1月18日 周三 21：5172012年1月19日 周四 22：0182012年1月20日 周五 21：4392012年1月21日 周六 21：35102012年1月22日 周日 21：53所有的时间都放在一起是没法分析的，接下来我就把各部分时间分离开，并转化成了整数型，这一步代码如下：</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/03/tackle-english-exam-with-text-mining/">
                <h3 class="media-heading">使用R语言文本挖掘技术应对英语考试的粗浅想法及其他</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Mar 3, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">学习与考试学习是由经验引起的相对持久的变化，而考试，一方面是对习得的知识与技能的掌握情况的测试，另一方面也是对能否进入下一阶段学习或工作的考核。虽然学习能力受个人的智力水平以及学习方法的影响，但一般而言，学习是没有捷径的；但考试却不一样，在应付考试的时候，确实存在一些捷径可走。且以我个人的经历举三个例子。
高中的时候，我的立体几何学得不是很好，对于如何解立体几何大题完全摸不着门路。然而有一天，我在一本辅导书中看到一种用空间向量解立体几何大题的方法，而且相当简单易学，做了几道类似的题，我就掌握了这个方法。随后在整个高中阶段，我就靠着这一捷径，在并不具备足够的立体几何知识的前提下做到了立体几何大题从来不丢分。
我本科是自考的英语专业，其中有一门课，叫《英美文学选读》。这门课应该是所有20多门课中最有价值的一门，同时也是最难的一门。教材中介绍了英国与美国的70多位著名的作家以及他们的代表作。我第一次没能考过，因为内容实在是太多了，不好把握重点。后来，我找了几份历年的真题，看过之后才发现，原来70多位作者当中，只有30多位会在考试中考到，这一下就把任务量缩减了一半。虽然难度还是挺大的，但第二次终于顺便通过了。我又一次找到了考试的捷径，同时也第一次意识到真题对于考试的重要性。
拿到本科毕业证之后，我就开始着手考研。专业课所涉及的内容不可谓不多，如果想全面的复习，时间肯定不够，只能有所侧重的进行复习。有了先前的经验，我开始反复地研究真题。哪些知识点会以选择题的形式考察，哪些知识点会以大题的形式考察，哪些部分的内容考试从来不涉及，可以忽略，哪些部分的内容频繁考到，必须重点记忆？经过反复地分析，我根据真题总结出了一份比较精简的笔记，并在考试中拿到了一个还算满意的分数。如果仅仅按大纲来复习的话，肯定会浪费很多时间。
从我个人经历来看，考试确实是有捷径可循，而这个捷径往往跟历年的真题有关。但是对于大部分考试来说，可用于分析的样本量太低，而且找不到客观的指标，只能通过自己的主观判断，因此在知识点的选取上难免会有一些偏差。但有一门考试却不存在这两个问题，既有足够大的样本量可供分析，又能产生客观的指标。很明显，这门考试就是大家“喜闻乐见”英语考试。
上大学之前，语数外三科同等重要；而上大学之后，大多数专业应该都不用学语文了，文科的一般也不用学数学了，只有英语，坚挺地为几乎所有专业所必学，并在很多学校作为毕业的条件之一。从这一点也可以看出来英语的重要性。学好英语不是一件轻松的事情，需要长时间的积累。虽然我恐怕不会再参加任何类型的英语考试了，但是未了将来的更好发展，我基本上保持着每天10K的英文阅读量。不过，应付英语考试就是另外一回事了，完全有可能出现我在备考《英美文学选读》时的情况。此外，我还想强调一点，我们这一辈子为了应付考试浪费了太多的生命了，也许功利地应付考试，反而倒是一种非功利的学习行为。
要准备英语考试，大部分人的第一反应应该都是要背单词！各个级别的英语考试都有那么几千到上万的单词需要背诵，绝大多数考生都或多或少地受到过背单词的折磨。背了忘，忘了再背，背了再忘，反反复复，没有休止。一方面，对单词的记忆会随着时间的流逝而消退，另一方面，几千个单词之间往往也会产生各种干扰，导致遗忘。如果需要背诵的单词量大大减少的话，情况就会好得多了。那现在的问题就是，各级别英语考试大纲中的那些单词，真的都需要背下来吗？
社会学中有个著名的80/20定律，即这个世界80%的财富都集中在20%的人手里。对于英语试卷这一定律可能也适用，即80%的文本都是由那20%最常见的单词组成。如果真是这样的话，那只需要原先五分之一的时间（也许更少，因为这时的干扰也更少），就足以应付英语考试了。市面上其实早就有了通过词频来排列单词供人背诵的参考书，但是这些书的销量似乎并不是很好，这大概是因为这些书只是笼统的把全部文本都拿来进行统计，不够细致，也没有针对性。如果能针对不同类型的试题，甚至针对这些试题的不同部分，统计出来词频，肯定会有更好的指导作用。
针对高考英语阅读题的文本分析为了进行验证与分析，我从网上找到了最近9年的天津高考英语试题文档。我把其中的阅读部分复制了出来，按年份保存在了txt文档中，然后利用tidyverse和tidytext包，制作了两份csv格式句子库文档，其中一份是以全部阅读文本为基础生成的，另一份则只针对阅读题的题干而生成。现在先载入需要的包，并把这两份数据导入：
library(tidyverse)library(tidytext)library(pipeR)library(magrittr)library(knitr)reading &lt;- read.csv(&#39;reading.csv&#39;, stringsAsFactors = FALSE)question &lt;- read.csv(&#39;question.csv&#39;, stringsAsFactors = FALSE)因为readr包中的函数对中文的支持不是很好，所以我这里使用了R自带的函数。先看一下这两份数据：
reading %&gt;% head() %&gt;% kable()yearregionpassagesentencesentence_low2007天津AThe city of Rome has passed a new law to prevent cruelty to animals.the city of rome has passed a new law to prevent cruelty to animals.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2018/02/stereotype-on-anime/">
                <h3 class="media-heading">关于动画的刻板印象</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2018
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">前段时间带孩子去看了《金龟子》动画大电影，感觉很无趣。我原以为其身为童年回忆，来到屏幕，面对长幼两辈，必有看点，没想到竟演出如此幼稚之戏！看了几分钟之后，我就开始玩手机了。坐我前面的也是一对父子，动画放了一半的时候，孩子问了他爸爸一句话，让我印象很深刻。他问：“爸爸，你怎么不看啊？”孩子显然是很喜欢这部动画的，希望他爸爸也跟他一起看，但这动画实在无法勾起我们的兴趣。电影结束回到家后，我产生了一个疑问，难道这部动画真的没办法制作成老少咸宜的吗？是出于什么原因，导致这部本来可以通过卖情怀让成年人也产生兴趣的动画最终只是一部低龄向动画？我想，原因不外乎在我们国家对于动画一直存在一个根深蒂固的刻板印象，即，动画是给小孩子看的。
小时候就经常听到大人们说，“你看谁谁谁，真是没出息，这么大了还看动画片。”我关于“动画是给小孩子看的”这一刻板印象应该就是那个时候形成的。不过，虽然有这么个刻板印象，我还是从小看到了大（别说，也确实没什么出息），因为在看的过程中，我并没有体验到“动画是给小孩子看的”这一点，不过大了之后，我从来不看国产动画就是了（除了陪孩子看《喜羊羊》《熊出没》之类的动画，不过说起来，好像连我家孩子也很少看这两部动画了），即便现在国产动画天天“崛起”，我也一丁点不想看。究其原因，大概是因为我关于动画的刻板印象在之前的基础之上发生了变化，变成了“国产动画是给小孩子看的”。
中学时一直在在追漫画《神兵玄奇》，后来听说要改编成动画了，挺激动的，谁知道改编成了《神兵小将》。这部时不时会有少儿不宜场景的成人向漫画到底经过了怎样的反向魔改才成为低龄向动画的？还是之前那个疑问，这部动画难道就不能通过适当的删改，制作成全年龄的吗？带着这种疑问，我试图去知网上寻找答案，我在检索处输入了“动画”一词，第一个匹配的关键词是“幼儿”，第二个是“身心发展”，看起来这一刻板印象确实是挺普遍的，连搞学术的人都这么认为了。我最终没能在知网上找到答案，所以我决定自己来对这一问题进行一下探究。
首先，我要确定两件事情：
关于动画是不是存在这样的刻板印象？
如果存在的话，这一刻板印象是仅限于我们国家，还是全都这样？
要进行验证的话，首先要有相关的数据。虽然我平常关于动画的信息会参考IMDB和MAL，但要完成这一任务，显然还是豆瓣更合适。我试图在豆瓣网站上爬取我所需要的信息，但折腾了一上午才发现，我所掌握的那一点点爬虫技术根本就无法爬取我所需要的数据，于是我就在网上找了一份现成的（早知道就不折腾了）。这份数据是2016年的，还算比较新，内容也完全符合我的需要。其次，要找到具有代表性的作品。关于哪些动画是代表性的，每个人肯定都有不同的看法，可能不会有特定的原型，所以这里我先用豆瓣上的评价人数为指标来评定动画的代表性，评价人数越多，就说明其越具有代表性。另外，要拿国产动画和国外动画进行对比，但实际上所谓的国外动画，主要就是美国和日本的动画（三个国家的动画数量占了全部动画数量的81.4%），所以后面只挑了这三个地区的数据。
先载入要用到的包：
library(tidyverse)library(knitr)library(scales)按照惯例，先载入了tidyverse包；然后为了数据能展示得更好看一点，以及数据的正常显示，也载入了knitr包；另外，后面在画图的时候，还要用到scales包，这里也一并载入。
然后来看一下这份数据：
douban &lt;- read_csv(&#39;douban.csv&#39;)## Parsed with column specification:## cols(## 评分 = col_double(),## 名字 = col_character(),## 投票人数 = col_integer(),## 类型 = col_character(),## 产地 = col_character(),## 上映时间 = col_character(),## 时长 = col_character(),## 年代 = col_character(),## 是否连续剧 = col_integer(),## 集数 = col_character(),## 看过 = col_integer(),## 待看 = col_character()## )head(douban, 10) %&gt;% kable()评分名字投票人数类型产地上映时间时长年代是否连续剧集数看过待看7.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         10 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/cover.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>



<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>




    
  </body>
</html>
